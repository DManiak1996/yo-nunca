{
  "title": "Chat Trigger node",
  "content": "Use the Chat Trigger node when building AI workflows for chatbots and other chat interfaces. You can configure how users access the chat, using one of n8n's provided interfaces, or your own. You can add authentication.\n\nYou must connect either an agent or chain [root node](../../cluster-nodes/root-nodes/).\n\nWorkflow execution usage\n\nEvery message to the Chat Trigger executes your workflow. This means that one conversation where a user sends 10 messages uses 10 executions from your execution allowance. Check your payment plan for details of your allowance.\n\nThis node replaces the Manual Chat Trigger node from version 1.24.0.\n\n### Make Chat Publicly Available\n\nSet whether the chat should be publicly available (turned on) or only available through the manual chat interface (turned off).\n\nLeave this turned off while you're building the workflow. Turn it on when you're ready to activate the workflow and allow users to access the chat.\n\nChoose how users access the chat. Select from:\n\n- **Hosted Chat**: Use n8n's hosted chat interface. Recommended for most users because you can configure the interface using the [node options](#node-options) and don't have to do any other setup.\n- **Embedded Chat**: This option requires you to create your own chat interface. You can use n8n's [chat widget](https://www.npmjs.com/package/@n8n/chat) or build your own. Your chat interface must call the webhook URL shown in **Chat URL** in the node.\n\nChoose whether and how to restrict access to the chat. Select from:\n\n- **None**: The chat doesn't use authentication. Anyone can use the chat.\n- **Basic Auth**: The chat uses basic authentication.\n  - Select or create a **Credential for Basic Auth** with a username and password. All users must use the same username and password.\n- **n8n User Auth**: Only users logged in to an n8n account can use the chat.\n\n### Initial Message(s)\n\nThis parameter's only available if you're using **Hosted Chat**. Use it to configure the message the n8n chat interface displays when the user arrives on the page.\n\nAvailable options depend on the chat mode.\n\n### Hosted chat options\n\n#### Allowed Origin (CORS)\n\nSet the origins that can access the chat URL. Enter a comma-separated list of URLs allowed for cross-origin non-preflight requests.\n\nUse `*` (default) to allow all origins.\n\n#### Input Placeholder, Title, and Subtitle\n\nEnter the text for these elements in the chat interface.\n\n#### Load Previous Session\n\nSelect whether to load chat messages from a previous chat session.\n\nIf you select any option other than **Off**, you must connect the Chat trigger and the Agent you're using to a memory sub-node. The memory connector on the Chat trigger appears when you set **Load Previous Session** to **From Memory**. n8n recommends connecting both the Chat trigger and Agent to the same memory sub-node, as this ensures a single source of truth for both nodes.\n\nUse this option when building a workflow with steps after the agent or chain that's handling the chat. Choose from:\n\n- **When Last Node Finishes**: The Chat Trigger node returns the response code and the data output from the last node executed in the workflow.\n- **Using Response Nodes**: The Chat Trigger node responds as defined in a [Respond to Chat](../n8n-nodes-langchain.respondtochat/) node or [Respond to Webhook](../n8n-nodes-base.respondtowebhook/) node. In this response mode, the Chat Trigger will solely show messages as defined in these nodes and not output the data from the last node executed in the workflow.\n\nThis mode replaces the 'Using Respond to Webhook Node' mode from version 1.2 of the Chat Trigger node.\n\n- **Streaming response**: Enables real-time data streaming back to the user as the workflow processes. Requires nodes with streaming support in the workflow (for example, the [AI agent](../../cluster-nodes/root-nodes/n8n-nodes-langchain.agent/) node).\n\n#### Require Button Click to Start Chat\n\nSet whether to display a **New Conversation** button on the chat interface (turned on) or not (turned off).\n\n### Embedded chat options\n\n#### Allowed Origin (CORS)\n\nSet the origins that can access the chat URL. Enter a comma-separated list of URLs allowed for cross-origin non-preflight requests.\n\nUse `*` (default) to allow all origins.\n\n#### Load Previous Session\n\nSelect whether to load chat messages from a previous chat session.\n\nIf you select any option other than **Off**, you must connect the Chat trigger and the Agent you're using to a memory sub-node. The memory connector on the Chat trigger appears when you set **Load Previous Session** to **From Memory**. n8n recommends connecting both the Chat trigger and Agent to the same memory sub-node, as this ensures a single source of truth for both nodes.\n\nUse this option when building a workflow with steps after the agent or chain that's handling the chat. Choose from:\n\n- **When Last Node Finishes**: The Chat Trigger node returns the response code and the data output from the last node executed in the workflow.\n- **Using Response Nodes**: The Chat Trigger node responds as defined in a [Respond to Chat](../n8n-nodes-langchain.respondtochat/) node or [Respond to Webhook](../n8n-nodes-base.respondtowebhook/) node. In this response mode, the Chat Trigger will solely show messages as defined in these nodes and not output the data from the last node executed in the workflow.\n\nThis mode replaces the 'Using Respond to Webhook Node' mode from version 1.2 of the Chat Trigger node.\n\n- **Streaming response**: Enables real-time data streaming back to the user as the workflow processes. Requires nodes with streaming support enabled.\n\n## Templates and examples\n\n**RAG Starter Template using Simple Vector Stores, Form trigger and OpenAI**\n\n[View template details](https://n8n.io/workflows/5010-rag-starter-template-using-simple-vector-stores-form-trigger-and-openai/)\n\n**Unify multiple triggers into a single workflow**\n\nby Guillaume Duvernay\n\n[View template details](https://n8n.io/workflows/7784-unify-multiple-triggers-into-a-single-workflow/)\n\n**Trigger Outbound Vapi AI Voice Calls From New Jotform Submissions**\n\n[View template details](https://n8n.io/workflows/6695-trigger-outbound-vapi-ai-voice-calls-from-new-jotform-submissions/)\n\n[Browse Chat Trigger integration templates](https://n8n.io/integrations/chat-trigger/), or [search all templates](https://n8n.io/workflows/)\n\nView n8n's [Advanced AI](../../../../advanced-ai/) documentation.\n\n## Set the chat response manually\n\nYou need to manually set the chat response when you don't want to directly send the output of an Agent or Chain node to the user. Instead, you want to take the output of an Agent or Chain node and modify it or do something else with it before sending it back to the user.\n\nIn a basic workflow, the Agent and Chain nodes output a parameter named either `output` or `text`, and the Chat trigger sends the value of this parameter to the user as the chat response.\n\nIf you need to manually create the response sent to the user, you must create a parameter named either `text` or `output`. If you use a different parameter name, the Chat trigger sends the entire object as its response, not just the value.\n\nWhen you are using a [Respond to Chat](../n8n-nodes-langchain.respondtochat/) node to manually create the response sent to the user, you must set the Chat Trigger response mode to 'Using Response Nodes'.\n\nFor common questions or issues and suggested solutions, refer to [Common Issues](common-issues/).",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Node parameters",
      "id": "node-parameters"
    },
    {
      "level": "h3",
      "text": "Make Chat Publicly Available",
      "id": "make-chat-publicly-available"
    },
    {
      "level": "h3",
      "text": "Mode",
      "id": "mode"
    },
    {
      "level": "h3",
      "text": "Authentication",
      "id": "authentication"
    },
    {
      "level": "h3",
      "text": "Initial Message(s)",
      "id": "initial-message(s)"
    },
    {
      "level": "h2",
      "text": "Node options",
      "id": "node-options"
    },
    {
      "level": "h3",
      "text": "Hosted chat options",
      "id": "hosted-chat-options"
    },
    {
      "level": "h3",
      "text": "Embedded chat options",
      "id": "embedded-chat-options"
    },
    {
      "level": "h2",
      "text": "Templates and examples",
      "id": "templates-and-examples"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Set the chat response manually",
      "id": "set-the-chat-response-manually"
    },
    {
      "level": "h2",
      "text": "Common issues",
      "id": "common-issues"
    }
  ],
  "url": "llms-txt#chat-trigger-node",
  "links": []
}