{
  "title": "Handling API rate limits",
  "content": "[API](../../../glossary/#api) rate limits are restrictions on request frequency. For example, an API may limit the number of requests you can make per minute, or per day.\n\nAPIs can also limits how much data you can send in one request, or how much data the API sends in a single response.\n\n## Identify rate limit issues\n\nWhen an n8n node hits a rate limit, it errors. n8n displays the error message in the node output panel. This includes the error message from the service.\n\nIf n8n received error 429 (too many requests) from the service, the error message is **The service is receiving too many requests from you**.\n\nTo check the rate limits for the service you're using, refer to the API documentation for the service.\n\n## Handle rate limits for integrations\n\nThere are two ways to handle rate limits in n8n's integrations: using the Retry On Fail setting, or using a combination of the [Loop Over Items](../core-nodes/n8n-nodes-base.splitinbatches/) and [Wait](../core-nodes/n8n-nodes-base.wait/) nodes:\n\n- Retry On Fail adds a pause between API request attempts.\n- With Loop Over Items and Wait you can break you request data into smaller chunks, as well as pausing between requests.\n\n### Enable Retry On Fail\n\nWhen you enable Retry On Fail, the node automatically tries the request again if it fails the first time.\n\n1. Open the node.\n1. Select **Settings**.\n1. Enable the **Retry On Fail** toggle.\n1. Configure the retry settings: if using this to work around rate limits, set **Wait Between Tries (ms)** to more than the rate limit. For example, if the API you're using allows one request per second, set **Wait Between Tries (ms)** to `1000` to allow a 1 second wait.\n\n### Use Loop Over Items and Wait\n\nUse the Loop Over Items node to batch the input items, and the Wait node to introduce a pause between each request.\n\n1. Add the Loop Over Items node before the node that calls the API. Refer to [Loop Over Items](../core-nodes/n8n-nodes-base.splitinbatches/) for information on how to configure the node.\n1. Add the Wait node after the node that calls the API, and connect it back to the Loop Over Items node. Refer to [Wait](../core-nodes/n8n-nodes-base.wait/) for information on how to configure the node.\n\nFor example, to handle rate limits when using OpenAI:\n\n## Handle rate limits in the HTTP Request node\n\nThe HTTP Request node has built-in settings for handling rate limits and large amounts of data.\n\nUse the Batching option to send more than one request, reducing the request size, and introducing a pause between requests. This is the equivalent of using Loop Over Items and Wait.\n\n1. In the HTTP Request node, select **Add Option** > **Batching**.\n1. Set **Items per Batch**: this is the number of input items to include in each request.\n1. Set **Batch Interval (ms)** to introduce a delay between requests. For example, if the API you're using allows one request per second, set **Wait Between Tries (ms)** to `1000` to allow a 1 second wait.\n\nAPIs paginate their results when they need to send more data than they can handle in a single response. For more information on pagination in the HTTP Request node, refer to [HTTP Request node | Pagination](../core-nodes/n8n-nodes-base.httprequest/#pagination).",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Identify rate limit issues",
      "id": "identify-rate-limit-issues"
    },
    {
      "level": "h2",
      "text": "Handle rate limits for integrations",
      "id": "handle-rate-limits-for-integrations"
    },
    {
      "level": "h3",
      "text": "Enable Retry On Fail",
      "id": "enable-retry-on-fail"
    },
    {
      "level": "h3",
      "text": "Use Loop Over Items and Wait",
      "id": "use-loop-over-items-and-wait"
    },
    {
      "level": "h2",
      "text": "Handle rate limits in the HTTP Request node",
      "id": "handle-rate-limits-in-the-http-request-node"
    },
    {
      "level": "h3",
      "text": "Batch requests",
      "id": "batch-requests"
    },
    {
      "level": "h3",
      "text": "Paginate results",
      "id": "paginate-results"
    }
  ],
  "url": "llms-txt#handling-api-rate-limits",
  "links": []
}