{
  "title": "Simple Memory node",
  "content": "Use the Simple Memory node to [persist](../../../../../glossary/#ai-memory) chat history in your workflow.\n\nOn this page, you'll find a list of operations the Simple Memory node supports, and links to more resources.\n\nDon't use this node if running n8n in queue mode\n\nIf your n8n instance uses [queue mode](../../../../../hosting/scaling/queue-mode/), this node doesn't work in an active production workflow. This is because n8n can't guarantee that every call to Simple Memory will go to the same worker.\n\nParameter resolution in sub-nodes\n\nSub-nodes behave differently to other nodes when processing multiple items using an expression.\n\nMost nodes, including root nodes, take any number of items as input, process these items, and output the results. You can use expressions to refer to input items, and the node resolves the expression for each item in turn. For example, given an input of five `name` values, the expression `{{ $json.name }}` resolves to each name in turn.\n\nIn sub-nodes, the expression always resolves to the first item. For example, given an input of five `name` values, the expression `{{ $json.name }}` always resolves to the first name.\n\nConfigure these parameters to configure the node:\n\n- **Session Key**: Enter the key to use to store the memory in the workflow data.\n- **Context Window Length**: Enter the number of previous interactions to consider for context.\n\n## Templates and examples\n\n**Chat with GitHub API Documentation: RAG-Powered Chatbot with Pinecone & OpenAI**\n\n[View template details](https://n8n.io/workflows/2705-chat-with-github-api-documentation-rag-powered-chatbot-with-pinecone-and-openai/)\n\n**ðŸ¤– Create a Documentation Expert Bot with RAG, Gemini, and Supabase**\n\n[View template details](https://n8n.io/workflows/5993-create-a-documentation-expert-bot-with-rag-gemini-and-supabase/)\n\n**ðŸ¤– Build a Documentation Expert Chatbot with Gemini RAG Pipeline**\n\n[View template details](https://n8n.io/workflows/6137-build-a-documentation-expert-chatbot-with-gemini-rag-pipeline/)\n\n[Browse Simple Memory node documentation integration templates](https://n8n.io/integrations/window-buffer-memory/), or [search all templates](https://n8n.io/workflows/)\n\nRefer to [LangChain's Buffer Window Memory documentation](https://v03.api.js.langchain.com/classes/langchain.memory.BufferWindowMemory.html) for more information about the service.\n\nView n8n's [Advanced AI](../../../../../advanced-ai/) documentation.\n\nFor common questions or issues and suggested solutions, refer to [Common issues](common-issues/).",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Node parameters",
      "id": "node-parameters"
    },
    {
      "level": "h2",
      "text": "Templates and examples",
      "id": "templates-and-examples"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Common issues",
      "id": "common-issues"
    }
  ],
  "url": "llms-txt#simple-memory-node",
  "links": []
}