{
  "title": "Evaluation node",
  "content": "The Evaluation node performs various operations related to [evaluations](../../../../advanced-ai/evaluations/overview/) to validate your AI workflow reliability.\n\nUse the Evaluation node in these scenarios:\n\n- To conditionally execute logic based on whether the workflow is under evaluation\n- To write evaluation outcomes back to a Google Sheet datasetor\n- To log scoring metrics for your evaluation performance to n8n's evaluations tab\n\nCredentials for Google Sheets\n\nThe Evaluation node's **Set Outputs** operation records evaluation results to data tables or Google Sheets. To use Google Sheets as a recording location, configure a [Google Sheets credential](../../credentials/google/).\n\nThe Evaluation node offers the following operations:\n\n- [**Set Outputs**](#set-outputs): Write the results of an evaluation back to a data table or Google Sheet dataset.\n- [**Set Metrics**](#set-metrics): Record metrics scoring the evaluation performance to n8n's **Evaluations** tab.\n- [**Check If Evaluating**](#check-if-evaluating): Branches the workflow execution logic depending on whether the current execution is an evaluation.\n\nThe parameters and options available depend on the operation you select.\n\nThe **Set Outputs** operation has the following parameters:\n\n- **Source:** Select the location to which you want to output the evaluation results. Default value is **Data table**.\n\nSource settings differ depending on **Source** selection.\n\nYou define the items to write to the data table or Google Sheet in the **Outputs** section. For each output, you set the following:\n\n- **Name**: The Google Sheet column name to write the evaluation results to.\n- **Value**: The value to write to the Google Sheet.\n\nThe **Set Metrics** operation includes a **Metrics to Return** section where you define the metrics to record and track for your evaluations. You can see the metric results in your workflow's **Evaluations** tab.\n\nFor each metric you wish to record, you set the following details:\n\n- **Name**: The name to use for the metric.\n- **Value**: The numeric value to record. Once you run your evaluation, you can drag and drop values from previous nodes here. Metric values must be numeric.\n\n### Check If Evaluating\n\nThe **Check If Evaluating** operation doesn't have any parameters. This operation provides branching output connectors so that you can conditionally execute logic depending on whether the current execution is an evaluation or not.\n\n## Templates and examples\n\n**AI Automated HR Workflow for CV Analysis and Candidate Evaluation**\n\n[View template details](https://n8n.io/workflows/2860-ai-automated-hr-workflow-for-cv-analysis-and-candidate-evaluation/)\n\n**HR Job Posting and Evaluation with AI**\n\n[View template details](https://n8n.io/workflows/2773-hr-job-posting-and-evaluation-with-ai/)\n\n**AI-Powered Candidate Screening and Evaluation Workflow using OpenAI and Airtable**\n\n[View template details](https://n8n.io/workflows/4481-ai-powered-candidate-screening-and-evaluation-workflow-using-openai-and-airtable/)\n\n[Browse Evaluation integration templates](https://n8n.io/integrations/evaluation/), or [search all templates](https://n8n.io/workflows/)\n\nTo learn more about n8n evaluations, check out the [evaluations documentation](../../../../advanced-ai/evaluations/overview/)\n\nn8n provides a trigger node for evaluations. You can find the node docs [here](../n8n-nodes-base.evaluationtrigger/).\n\nFor common questions or issues and suggested solutions, refer to the evaluations [tips and common issues](../../../../advanced-ai/evaluations/tips-and-common-issues/) page.",
  "code_samples": [
    {
      "code": "* When **Source** is **Data table**:\n    * **Data table:** Select a data table by name or ID\n* When **Source** is **Google Sheets**:\n    * **Credential to connect with**: Create or select an existing [Google Sheets credentials](/integrations/builtin/credentials/google/index.md).\n    * **Document Containing Dataset**: Choose the spreadsheet document you want to write the evaluation results to. Usually this is the same document you select in the [Evaluation Trigger](/integrations/builtin/core-nodes/n8n-nodes-base.evaluationtrigger.md) node.\n    * Select **From list** to choose the spreadsheet title from the dropdown list, **By URL** to enter the url of the spreadsheet, or **By ID** to enter the `spreadsheetId`. \n        * You can find the `spreadsheetId` in a Google Sheets URL: `https://docs.google.com/spreadsheets/d/spreadsheetId/edit#gid=0`.\n    * **Sheet Containing Dataset**: Choose the sheet you want to write the evaluation results to. Usually this is the same sheet you select in the [Evaluation Trigger](/integrations/builtin/core-nodes/n8n-nodes-base.evaluationtrigger.md) node.\n        * Select **From list** to choose the sheet title from the dropdown list, **By URL** to enter the url of the sheet, **By ID** to enter the `sheetId`, or **By Name** to enter the sheet title. \n        * You can find the `sheetId` in a Google Sheets URL: `https://docs.google.com/spreadsheets/d/aBC-123_xYz/edit#gid=sheetId`.",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Operations",
      "id": "operations"
    },
    {
      "level": "h3",
      "text": "Set Outputs",
      "id": "set-outputs"
    },
    {
      "level": "h3",
      "text": "Set Metrics",
      "id": "set-metrics"
    },
    {
      "level": "h3",
      "text": "Check If Evaluating",
      "id": "check-if-evaluating"
    },
    {
      "level": "h2",
      "text": "Templates and examples",
      "id": "templates-and-examples"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    }
  ],
  "url": "llms-txt#evaluation-node",
  "links": []
}