{
  "title": "OpenAI Functions Agent node",
  "content": "Use the OpenAI Functions Agent node to use an [OpenAI functions model](https://platform.openai.com/docs/guides/function-calling). These are models that detect when a function should be called and respond with the inputs that should be passed to the function.\n\nRefer to [AI Agent](../) for more information on the AI Agent node itself.\n\nYou can use this agent with the [Chat Trigger](../../../../core-nodes/n8n-nodes-langchain.chattrigger/) node. Attach a memory sub-node so that users can have an ongoing conversation with multiple queries. Memory doesn't persist between sessions.\n\nOpenAI Chat Model required\n\nYou must use the [OpenAI Chat Model](../../../sub-nodes/n8n-nodes-langchain.lmchatopenai/) with this agent.\n\nConfigure the OpenAI Functions Agent using the following parameters.\n\nSelect how you want the node to construct the prompt (also known as the user's query or input from the chat).\n\n- **Take from previous node automatically**: If you select this option, the node expects an input from a previous node called `chatInput`.\n- **Define below**: If you select this option, provide either static text or an expression for dynamic content to serve as the prompt in the **Prompt (User Message)** field.\n\n### Require Specific Output Format\n\nThis parameter controls whether you want the node to require a specific output format. When turned on, n8n prompts you to connect one of these output parsers to the node:\n\n- [Auto-fixing Output Parser](../../../sub-nodes/n8n-nodes-langchain.outputparserautofixing/)\n- [Item List Output Parser](../../../sub-nodes/n8n-nodes-langchain.outputparseritemlist/)\n- [Structured Output Parser](../../../sub-nodes/n8n-nodes-langchain.outputparserstructured/)\n\nRefine the OpenAI Functions Agent node's behavior using these options:\n\nIf you'd like to send a message to the agent before the conversation starts, enter the message you'd like to send.\n\nUse this option to guide the agent's decision-making.\n\nEnter the number of times the model should run to try and generate a good answer from the user's prompt.\n\n### Return Intermediate Steps\n\nSelect whether to include intermediate steps the agent took in the final output (turned on) or not (turned off).\n\nThis could be useful for further refining the agent's behavior based on the steps it took.\n\n## Templates and examples\n\nRefer to the main AI Agent node's [Templates and examples](../#templates-and-examples) section.\n\nFor common questions or issues and suggested solutions, refer to [Common issues](../common-issues/).",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Node parameters",
      "id": "node-parameters"
    },
    {
      "level": "h3",
      "text": "Prompt",
      "id": "prompt"
    },
    {
      "level": "h3",
      "text": "Require Specific Output Format",
      "id": "require-specific-output-format"
    },
    {
      "level": "h2",
      "text": "Node options",
      "id": "node-options"
    },
    {
      "level": "h3",
      "text": "System Message",
      "id": "system-message"
    },
    {
      "level": "h3",
      "text": "Max Iterations",
      "id": "max-iterations"
    },
    {
      "level": "h3",
      "text": "Return Intermediate Steps",
      "id": "return-intermediate-steps"
    },
    {
      "level": "h2",
      "text": "Templates and examples",
      "id": "templates-and-examples"
    },
    {
      "level": "h2",
      "text": "Common issues",
      "id": "common-issues"
    }
  ],
  "url": "llms-txt#openai-functions-agent-node",
  "links": []
}