{
  "title": "Thinking",
  "content": "Source: https://docs.ollama.com/capabilities/thinking\n\nThinking-capable models emit a `thinking` field that separates their reasoning trace from the final answer.\n\nUse this capability to audit model steps, animate the model *thinking* in a UI, or hide the trace entirely when you only need the final response.\n\n* [Qwen 3](https://ollama.com/library/qwen3)\n* [GPT-OSS](https://ollama.com/library/gpt-oss) *(use `think` levels: `low`, `medium`, `high` â€” the trace cannot be fully disabled)*\n* [DeepSeek-v3.1](https://ollama.com/library/deepseek-v3.1)\n* [DeepSeek R1](https://ollama.com/library/deepseek-r1)\n* Browse the latest additions under [thinking models](https://ollama.com/search?c=thinking)\n\n## Enable thinking in API calls\n\nSet the `think` field on chat or generate requests. Most models accept booleans (`true`/`false`).\n\nGPT-OSS instead expects one of `low`, `medium`, or `high` to tune the trace length.\n\nThe `message.thinking` (chat endpoint) or `thinking` (generate endpoint) field contains the reasoning trace while `message.content` / `response` holds the final answer.\n\n<Tabs>\n  <Tab title=\"cURL\">\n    \n  </Tab>\n\n<Tab title=\"Python\">\n    \n  </Tab>\n\n<Tab title=\"JavaScript\">\n    \n  </Tab>\n</Tabs>\n\n<Note>\n  GPT-OSS requires `think` to be set to `\"low\"`, `\"medium\"`, or `\"high\"`. Passing `true`/`false` is ignored for that model.\n</Note>\n\n## Stream the reasoning trace\n\nThinking streams interleave reasoning tokens before answer tokens. Detect the first `thinking` chunk to render a \"thinking\" section, then switch to the final reply once `message.content` arrives.\n\n<Tabs>\n  <Tab title=\"Python\">\n    \n  </Tab>\n\n<Tab title=\"JavaScript\">\n    \n  </Tab>\n</Tabs>\n\n## CLI quick reference\n\n* Enable thinking for a single run: `ollama run deepseek-r1 --think \"Where should I visit in Lisbon?\"`\n* Disable thinking: `ollama run deepseek-r1 --think=false \"Summarize this article\"`\n* Hide the trace while still using a thinking model: `ollama run deepseek-r1 --hidethinking \"Is 9.9 bigger or 9.11?\"`\n* Inside interactive sessions, toggle with `/set think` or `/set nothink`.\n* GPT-OSS only accepts levels: `ollama run gpt-oss --think=low \"Draft a headline\"` (replace `low` with `medium` or `high` as needed).\n\n<Note>Thinking is enabled by default in the CLI and API for supported models.</Note>",
  "code_samples": [
    {
      "code": "</Tab>\n\n  <Tab title=\"Python\">",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"JavaScript\">",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n</Tabs>\n\n<Note>\n  GPT-OSS requires `think` to be set to `\"low\"`, `\"medium\"`, or `\"high\"`. Passing `true`/`false` is ignored for that model.\n</Note>\n\n## Stream the reasoning trace\n\nThinking streams interleave reasoning tokens before answer tokens. Detect the first `thinking` chunk to render a \"thinking\" section, then switch to the final reply once `message.content` arrives.\n\n<Tabs>\n  <Tab title=\"Python\">",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"JavaScript\">",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Supported models",
      "id": "supported-models"
    },
    {
      "level": "h2",
      "text": "Enable thinking in API calls",
      "id": "enable-thinking-in-api-calls"
    },
    {
      "level": "h2",
      "text": "Stream the reasoning trace",
      "id": "stream-the-reasoning-trace"
    },
    {
      "level": "h2",
      "text": "CLI quick reference",
      "id": "cli-quick-reference"
    }
  ],
  "url": "llms-txt#thinking",
  "links": []
}