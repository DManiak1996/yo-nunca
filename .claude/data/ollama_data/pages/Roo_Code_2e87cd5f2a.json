{
  "title": "Roo Code",
  "content": "Source: https://docs.ollama.com/integrations/roo-code\n\nInstall [Roo Code](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline) from the VS Code Marketplace.\n\n1. Open Roo Code in VS Code and click the **gear icon** on the top right corner of the Roo Code window to open **Provider Settings**\n2. Set `API Provider` to `Ollama`\n3. (Optional) Update `Base URL` if your Ollama instance is running remotely. The default is `http://localhost:11434`\n4. Enter a valid `Model ID` (for example `qwen3` or `qwen3-coder:480b-cloud`)\n5. Adjust the `Context Window` to at least 32K tokens for coding tasks\n\n<Note>Coding tools require a larger context window. It is recommended to use a context window of at least 32K tokens. See [Context length](/context-length) for more information.</Note>\n\n## Connecting to ollama.com\n\n1. Create an [API key](https://ollama.com/settings/keys) from ollama.com\n2. Enable `Use custom base URL` and set it to `https://ollama.com`\n3. Enter your **Ollama API Key**\n4. Select a model from the list\n\n### Recommended Models\n\n* `qwen3-coder:480b`\n* `deepseek-v3.1:671b`",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Install",
      "id": "install"
    },
    {
      "level": "h2",
      "text": "Usage with Ollama",
      "id": "usage-with-ollama"
    },
    {
      "level": "h2",
      "text": "Connecting to ollama.com",
      "id": "connecting-to-ollama.com"
    },
    {
      "level": "h3",
      "text": "Recommended Models",
      "id": "recommended-models"
    }
  ],
  "url": "llms-txt#roo-code",
  "links": []
}