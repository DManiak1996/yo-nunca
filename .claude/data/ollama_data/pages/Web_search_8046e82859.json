{
  "title": "Web search",
  "content": "Source: https://docs.ollama.com/capabilities/web-search\n\nOllama's web search API can be used to augment models with the latest information to reduce hallucinations and improve accuracy.\n\nWeb search is provided as a REST API with deeper tool integrations in the Python and JavaScript libraries. This also enables models like OpenAI’s gpt-oss models to conduct long-running research tasks.\n\nFor access to Ollama's web search API, create an [API key](https://ollama.com/settings/keys). A free Ollama account is required.\n\nPerforms a web search for a single query and returns relevant results.\n\n`POST https://ollama.com/api/web_search`\n\n* `query` (string, required): the search query string\n* `max_results` (integer, optional): maximum results to return (default 5, max 10)\n\nReturns an object containing:\n\n* `results` (array): array of search result objects, each containing:\n  * `title` (string): the title of the web page\n  * `url` (string): the URL of the web page\n  * `content` (string): relevant content snippet from the web page\n\n<Note>\n  Ensure OLLAMA\\_API\\_KEY is set or it must be passed in the Authorization header.\n</Note>\n\nMore Ollama [Python example](https://github.com/ollama/ollama-python/blob/main/examples/web-search.py)\n\n#### JavaScript Library\n\nMore Ollama [JavaScript example](https://github.com/ollama/ollama-js/blob/main/examples/websearch/websearch-tools.ts)\n\nFetches a single web page by URL and returns its content.\n\n`POST https://ollama.com/api/web_fetch`\n\n* `url` (string, required): the URL to fetch\n\nReturns an object containing:\n\n* `title` (string): the title of the web page\n* `content` (string): the main content of the web page\n* `links` (array): array of links found on the page\n\n## Building a search agent\n\nUse Ollama’s web search API as a tool to build a mini search agent.\n\nThis example uses Alibaba’s Qwen 3 model with 4B parameters.\n\n### Context length and agents\n\nWeb search results can return thousands of tokens. It is recommended to increase the context length of the model to at least \\~32000 tokens. Search agents work best with full context length. [Ollama's cloud models](https://docs.ollama.com/cloud) run at the full context length.\n\nYou can enable web search in any MCP client through the [Python MCP server](https://github.com/ollama/ollama-python/blob/main/examples/web-search-mcp.py).\n\nOllama's web search can be integrated with Cline easily using the MCP server configuration.\n\n`Manage MCP Servers` > `Configure MCP Servers` > Add the following configuration:\n\n<img src=\"https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=046239fbe74a8e928752b97b1a8954fa\" alt=\"Cline MCP Configuration\" data-og-width=\"852\" width=\"852\" data-og-height=\"1078\" height=\"1078\" data-path=\"images/cline-mcp.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=280&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=251a7ae4c99cafbeff8867a3cdefc854 280w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=560&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=bde250f5b99530b1870b5e7069abf10c 560w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=840&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=067e154d817a737cd508f74cffa77294 840w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=1100&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=c5db90800a313a6b262fcd37ab5be97f 1100w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=1650&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=1c20c4081d1e8f13a3da2348c6df1fd0 1650w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=2500&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=2dbaea69c8eefd988ec6c065ce966187 2500w\" />\n\nOllama works well with OpenAI's Codex tool.\n\nAdd the following configuration to `~/.codex/config.toml`\n\n<img src=\"https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/codex-mcp.png?fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=775b41bb85af7836b0a5a609de7d1f6f\" alt=\"Codex MCP Configuration\" data-og-width=\"1150\" width=\"1150\" data-og-height=\"1014\" height=\"1014\" data-path=\"images/codex-mcp.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/codex-mcp.png?w=280&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=165618dddf9daa7f355f71c454ba3f41 280w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/codex-mcp.png?w=560&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=79585e40dfb53f5fffc4a637a5119118 560w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/codex-mcp.png?w=840&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=ca1d7acc055ebdbc409d9f372d9ca3e5 840w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/codex-mcp.png?w=1100&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=603c85032a6b8dd755950c9d29f8fd21 1100w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/codex-mcp.png?w=1650&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=07665e9ee289fdabb9addde3a06bca7a 1650w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/codex-mcp.png?w=2500&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=f885735a8b1c269439f9ccf10424421e 2500w\" />\n\nOllama can integrate with Goose via its MCP feature.\n\n<img src=\"https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-1.png?fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=5fea6e0aab7865dc950470f004c549e8\" alt=\"Goose MCP Configuration 1\" data-og-width=\"1152\" width=\"1152\" data-og-height=\"1012\" height=\"1012\" data-path=\"images/goose-mcp-1.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-1.png?w=280&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=f7ccec9b53d39d84ed10bdedd0335e33 280w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-1.png?w=560&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=cb5464f221b561eba98c10702222d4fe 560w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-1.png?w=840&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=0810ea78c85815474a17d5c1d975771a 840w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-1.png?w=1100&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=67467cb3aaab1183f1f850a4061a7af0 1100w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-1.png?w=1650&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=2e8e9d972510ba17d542156b8c7a5142 1650w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-1.png?w=2500&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=f990a9ba7d6daf66e89699617034e6b9 2500w\" />\n\n<img src=\"https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-2.png?fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=c69c12389f7dd60ef1c53cd10af82a7d\" alt=\"Goose MCP Configuration 2\" data-og-width=\"1146\" width=\"1146\" data-og-height=\"1006\" height=\"1006\" data-path=\"images/goose-mcp-2.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-2.png?w=280&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=498deaa0c52aa33e32f4962e0dea9dc7 280w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-2.png?w=560&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=bb62f0113619a0f572e0017849a65bb5 560w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-2.png?w=840&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=7035aae8c4163df72f38d885f11e3f1c 840w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-2.png?w=1100&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=ca8a2966d7c350c6d75d9252f86f7be8 1100w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-2.png?w=1650&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=a488d0de5bf91dccd78a5187e712ceb2 1650w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/goose-mcp-2.png?w=2500&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=fa84ce84ab908bacd6853048972bff7c 2500w\" />\n\n### Other integrations\n\nOllama can be integrated into most of the tools available either through direct integration of Ollama's API, Python / JavaScript libraries, OpenAI compatible API, and MCP server integration.",
  "code_samples": [
    {
      "code": "**Response**",
      "language": "unknown"
    },
    {
      "code": "#### Python library",
      "language": "unknown"
    },
    {
      "code": "**Example output**",
      "language": "unknown"
    },
    {
      "code": "More Ollama [Python example](https://github.com/ollama/ollama-python/blob/main/examples/web-search.py)\n\n#### JavaScript Library",
      "language": "unknown"
    },
    {
      "code": "**Example output**",
      "language": "unknown"
    },
    {
      "code": "More Ollama [JavaScript example](https://github.com/ollama/ollama-js/blob/main/examples/websearch/websearch-tools.ts)\n\n## Web fetch API\n\nFetches a single web page by URL and returns its content.\n\n### Request\n\n`POST https://ollama.com/api/web_fetch`\n\n* `url` (string, required): the URL to fetch\n\n### Response\n\nReturns an object containing:\n\n* `title` (string): the title of the web page\n* `content` (string): the main content of the web page\n* `links` (array): array of links found on the page\n\n### Examples\n\n#### cURL Request",
      "language": "unknown"
    },
    {
      "code": "**Response**",
      "language": "unknown"
    },
    {
      "code": "#### Python SDK",
      "language": "unknown"
    },
    {
      "code": "**Result**",
      "language": "unknown"
    },
    {
      "code": "#### JavaScript SDK",
      "language": "unknown"
    },
    {
      "code": "**Result**",
      "language": "unknown"
    },
    {
      "code": "## Building a search agent\n\nUse Ollama’s web search API as a tool to build a mini search agent.\n\nThis example uses Alibaba’s Qwen 3 model with 4B parameters.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "**Result**",
      "language": "unknown"
    },
    {
      "code": "### Context length and agents\n\nWeb search results can return thousands of tokens. It is recommended to increase the context length of the model to at least \\~32000 tokens. Search agents work best with full context length. [Ollama's cloud models](https://docs.ollama.com/cloud) run at the full context length.\n\n## MCP Server\n\nYou can enable web search in any MCP client through the [Python MCP server](https://github.com/ollama/ollama-python/blob/main/examples/web-search-mcp.py).\n\n### Cline\n\nOllama's web search can be integrated with Cline easily using the MCP server configuration.\n\n`Manage MCP Servers` > `Configure MCP Servers` > Add the following configuration:",
      "language": "unknown"
    },
    {
      "code": "<img src=\"https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=046239fbe74a8e928752b97b1a8954fa\" alt=\"Cline MCP Configuration\" data-og-width=\"852\" width=\"852\" data-og-height=\"1078\" height=\"1078\" data-path=\"images/cline-mcp.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=280&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=251a7ae4c99cafbeff8867a3cdefc854 280w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=560&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=bde250f5b99530b1870b5e7069abf10c 560w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=840&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=067e154d817a737cd508f74cffa77294 840w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=1100&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=c5db90800a313a6b262fcd37ab5be97f 1100w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=1650&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=1c20c4081d1e8f13a3da2348c6df1fd0 1650w, https://mintcdn.com/ollama-9269c548/lS1IbrlCxMxm029K/images/cline-mcp.png?w=2500&fit=max&auto=format&n=lS1IbrlCxMxm029K&q=85&s=2dbaea69c8eefd988ec6c065ce966187 2500w\" />\n\n### Codex\n\nOllama works well with OpenAI's Codex tool.\n\nAdd the following configuration to `~/.codex/config.toml`",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Authentication",
      "id": "authentication"
    },
    {
      "level": "h2",
      "text": "Web search API",
      "id": "web-search-api"
    },
    {
      "level": "h3",
      "text": "Request",
      "id": "request"
    },
    {
      "level": "h3",
      "text": "Response",
      "id": "response"
    },
    {
      "level": "h3",
      "text": "Examples",
      "id": "examples"
    },
    {
      "level": "h2",
      "text": "Web fetch API",
      "id": "web-fetch-api"
    },
    {
      "level": "h3",
      "text": "Request",
      "id": "request"
    },
    {
      "level": "h3",
      "text": "Response",
      "id": "response"
    },
    {
      "level": "h3",
      "text": "Examples",
      "id": "examples"
    },
    {
      "level": "h2",
      "text": "Building a search agent",
      "id": "building-a-search-agent"
    },
    {
      "level": "h3",
      "text": "Context length and agents",
      "id": "context-length-and-agents"
    },
    {
      "level": "h2",
      "text": "MCP Server",
      "id": "mcp-server"
    },
    {
      "level": "h3",
      "text": "Cline",
      "id": "cline"
    },
    {
      "level": "h3",
      "text": "Codex",
      "id": "codex"
    },
    {
      "level": "h3",
      "text": "Goose",
      "id": "goose"
    },
    {
      "level": "h3",
      "text": "Other integrations",
      "id": "other-integrations"
    }
  ],
  "url": "llms-txt#web-search",
  "links": []
}