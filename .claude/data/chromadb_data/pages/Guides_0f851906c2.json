{
  "title": "Guides",
  "content": "- [Building with AI](https://docs.trychroma.com/guides/build/building-with-ai.md): The page explains how large language models (LLMs) can be used as a programming primitive to easily extract names from text, illustrating the process through code examples using OpenAI and Anthropic APIs in both Python and TypeScript.\n- [Introduction to Retrieval](https://docs.trychroma.com/guides/build/intro-to-retrieval.md): The page introduces the concept of retrieval in AI applications, explaining how retrieval systems like Chroma can address limitations of large language models by storing and retrieving data contextually, thus enhancing the accuracy and efficiency of response generation in applications like customer support.\n- [AWS Deployment](https://docs.trychroma.com/guides/deploy/aws.md): The page provides a detailed guide on deploying Chroma to AWS using a CloudFormation template, covering necessary steps, prerequisites, and configuration options.\n- [Azure Deployment](https://docs.trychroma.com/guides/deploy/azure.md): The page provides instructions for deploying Chroma on Azure using Terraform, including steps for installation, configuration, client set-up, and observability enhancements with OpenTelemetry.\n- [Running Chroma in Client-Server Mode](https://docs.trychroma.com/guides/deploy/client-server-mode.md): The page provides instructions for running Chroma in client-server mode, detailing how to set it up using both Python and TypeScript clients, and suggesting deployment options using Docker or cloud providers.\n- [Docker](https://docs.trychroma.com/guides/deploy/docker.md): The page provides instructions on running Chroma in a Docker container, configuring it with a YAML file, and setting up observability using OpenTelemetry and Zipkin with Docker Compose.\n- [GCP Deployment](https://docs.trychroma.com/guides/deploy/gcp.md): The page provides a guide for deploying Chroma on Google Cloud Platform using Terraform, including setup instructions, customization options, client configuration, and observability features.\n- [Observability](https://docs.trychroma.com/guides/deploy/observability.md): The page details Chroma's observability features, focusing on backend observability using OpenTelemetry for tracing and providing configuration instructions, as well as client observability via integrations with various platforms.\n- [Single-Node Chroma: Performance and Limitations](https://docs.trychroma.com/guides/deploy/performance.md): The page covers the performance and limitations of single-node Chroma, detailing its deployment advantages, stress test results, latency considerations, and system requirements for effective use with large-scale embeddings.\n- [Chroma's Thin-Client](https://docs.trychroma.com/guides/deploy/python-thin-client.md): The page describes Chroma's lightweight client-only library for running in client-server mode, explaining installation and usage of the `chromadb-client` package instead of the full `chromadb` package.\n- [](https://docs.trychroma.com/guides/develop/fast-api.md): The page is about integrating Chroma with FastAPI, detailing how to set up and use Chroma within a FastAPI application.\n- [](https://docs.trychroma.com/guides/develop/next-js.md): The page provides documentation about integrating and using Chroma with Next.js applications.",
  "code_samples": [],
  "headings": [],
  "url": "llms-txt#guides",
  "links": []
}