# Repository File Structure

Total items: 3643

```
ğŸ“ .buildkite
ğŸ“„ .clang-format
ğŸ“„ .coveragerc
ğŸ“„ .dockerignore
ğŸ“ .gemini
ğŸ“„ .git-blame-ignore-revs
ğŸ“ .github
ğŸ“„ .gitignore
ğŸ“„ .markdownlint.yaml
ğŸ“„ .pre-commit-config.yaml
ğŸ“„ .readthedocs.yaml
ğŸ“„ .shellcheckrc
ğŸ“„ .yapfignore
ğŸ“„ CMakeLists.txt
ğŸ“„ CODE_OF_CONDUCT.md
ğŸ“„ CONTRIBUTING.md
ğŸ“„ DCO
ğŸ“„ LICENSE
ğŸ“„ MANIFEST.in
ğŸ“„ README.md
ğŸ“„ RELEASE.md
ğŸ“„ SECURITY.md
ğŸ“ benchmarks
ğŸ“ cmake
ğŸ“„ codecov.yml
ğŸ“ csrc
ğŸ“ docker
ğŸ“ docs
ğŸ“ examples
ğŸ“„ format.sh
ğŸ“„ mkdocs.yaml
ğŸ“„ pyproject.toml
ğŸ“ requirements
ğŸ“„ setup.py
ğŸ“ tests
ğŸ“ tools
ğŸ“„ use_existing_torch.py
ğŸ“ vllm
  ğŸ“„ check-wheel-size.py
  ğŸ“„ generate_index.py
  ğŸ“ lm-eval-harness
  ğŸ“ performance-benchmarks
  ğŸ“„ release-pipeline.yaml
  ğŸ“ scripts
  ğŸ“„ test-amd.yaml
  ğŸ“„ test-pipeline.yaml
  ğŸ“„ config.yaml
  ğŸ“„ .bc-linter.yml
  ğŸ“„ CODEOWNERS
  ğŸ“„ FUNDING.yml
  ğŸ“ ISSUE_TEMPLATE
  ğŸ“„ PULL_REQUEST_TEMPLATE.md
  ğŸ“„ dependabot.yml
  ğŸ“„ mergify.yml
  ğŸ“„ scale-config.yml
  ğŸ“ scripts
  ğŸ“ workflows
  ğŸ“„ README.md
  ğŸ“ auto_tune
  ğŸ“„ backend_request_func.py
  ğŸ“„ benchmark_block_pool.py
  ğŸ“„ benchmark_latency.py
  ğŸ“„ benchmark_long_document_qa_throughput.py
  ğŸ“„ benchmark_ngram_proposer.py
  ğŸ“„ benchmark_prefix_caching.py
  ğŸ“„ benchmark_prioritization.py
  ğŸ“„ benchmark_serving.py
  ğŸ“„ benchmark_serving_structured_output.py
  ğŸ“„ benchmark_throughput.py
  ğŸ“„ benchmark_utils.py
  ğŸ“ cutlass_benchmarks
  ğŸ“ disagg_benchmarks
  ğŸ“ fused_kernels
  ğŸ“ kernels
  ğŸ“ multi_turn
  ğŸ“ overheads
  ğŸ“„ run_structured_output_benchmark.sh
  ğŸ“„ sonnet.txt
  ğŸ“ structured_schemas
  ğŸ“„ cpu_extension.cmake
  ğŸ“ external_projects
  ğŸ“„ hipify.py
  ğŸ“„ utils.cmake
  ğŸ“„ activation_kernels.cu
  ğŸ“ attention
  ğŸ“„ cache.h
  ğŸ“„ cache_kernels.cu
  ğŸ“ core
  ğŸ“ cpu
  ğŸ“„ cub_helpers.h
  ğŸ“„ cuda_compat.h
  ğŸ“„ cuda_utils.h
  ğŸ“„ cuda_utils_kernels.cu
  ğŸ“„ cuda_view.cu
  ğŸ“„ cumem_allocator.cpp
  ğŸ“„ custom_all_reduce.cu
  ğŸ“„ custom_all_reduce.cuh
  ğŸ“„ custom_all_reduce_test.cu
  ğŸ“„ custom_quickreduce.cu
  ğŸ“ cutlass_extensions
  ğŸ“„ dispatch_utils.h
  ğŸ“„ launch_bounds_utils.h
  ğŸ“„ layernorm_kernels.cu
  ğŸ“„ layernorm_quant_kernels.cu
  ğŸ“ mamba
  ğŸ“ moe
  ğŸ“„ ops.h
  ğŸ“„ permute_cols.cu
  ğŸ“„ pos_encoding_kernels.cu
  ğŸ“ quantization
  ğŸ“ quickreduce
  ğŸ“ rocm
  ğŸ“„ sampler.cu
  ğŸ“ sparse
  ğŸ“„ torch_bindings.cpp
  ğŸ“„ type_convert.cuh
  ğŸ“„ Dockerfile
  ğŸ“„ Dockerfile.cpu
  ğŸ“„ Dockerfile.nightly_torch
  ğŸ“„ Dockerfile.ppc64le
  ğŸ“„ Dockerfile.rocm
  ğŸ“„ Dockerfile.rocm_base
  ğŸ“„ Dockerfile.s390x
  ğŸ“„ Dockerfile.tpu
  ğŸ“„ Dockerfile.xpu
  ğŸ“„ .nav.yml
  ğŸ“„ README.md
  ğŸ“ api
  ğŸ“ assets
  ğŸ“ cli
  ğŸ“ community
  ğŸ“ configuration
  ğŸ“ contributing
  ğŸ“ deployment
  ğŸ“ design
  ğŸ“ examples
  ğŸ“ features
  ğŸ“ getting_started
  ğŸ“ mkdocs
  ğŸ“ models
  ğŸ“ serving
  ğŸ“ training
  ğŸ“ usage
  ğŸ“ offline_inference
  ğŸ“ online_serving
  ğŸ“ others
  ğŸ“„ template_alpaca.jinja
  ğŸ“„ template_baichuan.jinja
  ğŸ“„ template_chatglm.jinja
  ğŸ“„ template_chatglm2.jinja
  ğŸ“„ template_chatml.jinja
  ğŸ“„ template_dse_qwen2_vl.jinja
  ğŸ“„ template_falcon.jinja
  ğŸ“„ template_falcon_180b.jinja
  ğŸ“„ template_inkbot.jinja
  ğŸ“„ template_teleflm.jinja
  ğŸ“„ template_vlm2vec_phi3v.jinja
  ğŸ“„ template_vlm2vec_qwen2vl.jinja
  ğŸ“„ tool_chat_template_deepseekr1.jinja
  ğŸ“„ tool_chat_template_deepseekv3.jinja
  ğŸ“„ tool_chat_template_deepseekv31.jinja
  ğŸ“„ tool_chat_template_gemma3_pythonic.jinja
  ğŸ“„ tool_chat_template_granite.jinja
  ğŸ“„ tool_chat_template_granite_20b_fc.jinja
  ğŸ“„ tool_chat_template_hermes.jinja
  ğŸ“„ tool_chat_template_hunyuan_a13b.jinja
  ğŸ“„ tool_chat_template_internlm2_tool.jinja
  ğŸ“„ tool_chat_template_llama3.1_json.jinja
  ğŸ“„ tool_chat_template_llama3.2_json.jinja
  ğŸ“„ tool_chat_template_llama3.2_pythonic.jinja
  ğŸ“„ tool_chat_template_llama4_json.jinja
  ğŸ“„ tool_chat_template_llama4_pythonic.jinja
  ğŸ“„ tool_chat_template_minimax_m1.jinja
  ğŸ“„ tool_chat_template_mistral.jinja
  ğŸ“„ tool_chat_template_mistral3.jinja
  ğŸ“„ tool_chat_template_mistral_parallel.jinja
  ğŸ“„ tool_chat_template_phi4_mini.jinja
  ğŸ“„ tool_chat_template_qwen3coder.jinja
  ğŸ“„ tool_chat_template_toolace.jinja
  ğŸ“„ tool_chat_template_xlam_llama.jinja
  ğŸ“„ tool_chat_template_xlam_qwen.jinja
  ğŸ“„ build.txt
  ğŸ“„ common.txt
  ğŸ“„ cpu-build.txt
  ğŸ“„ cpu.txt
  ğŸ“„ cuda.txt
  ğŸ“„ dev.txt
  ğŸ“„ docs.txt
  ğŸ“„ kv_connectors.txt
  ğŸ“„ lint.txt
  ğŸ“„ nightly_torch_test.txt
  ğŸ“„ rocm-build.txt
  ğŸ“„ rocm-test.txt
  ğŸ“„ rocm.txt
  ğŸ“„ test.in
  ğŸ“„ test.txt
  ğŸ“„ tpu.txt
  ğŸ“„ xpu.txt
  ğŸ“„ __init__.py
  ğŸ“ basic_correctness
  ğŸ“ benchmarks
  ğŸ“„ ci_envs.py
  ğŸ“ compile
  ğŸ“ config
  ğŸ“„ conftest.py
  ğŸ“ cuda
  ğŸ“ detokenizer
  ğŸ“ distributed
  ğŸ“ engine
  ğŸ“ entrypoints
  ğŸ“ evals
  ğŸ“ kernels
  ğŸ“ kv_transfer
  ğŸ“ lora
  ğŸ“ model_executor
  ğŸ“ models
  ğŸ“ multimodal
  ğŸ“ plugins
  ğŸ“ plugins_tests
  ğŸ“ prompts
  ğŸ“ quantization
  ğŸ“ reasoning
  ğŸ“ samplers
  ğŸ“ standalone_tests
  ğŸ“ system_messages
  ğŸ“„ test_config.py
  ğŸ“„ test_embedded_commit.py
  ğŸ“„ test_envs.py
  ğŸ“„ test_inputs.py
  ğŸ“„ test_logger.py
  ğŸ“„ test_outputs.py
  ğŸ“„ test_pooling_params.py
  ğŸ“„ test_regression.py
  ğŸ“„ test_routing_simulator.py
  ğŸ“„ test_scalartype.py
  ğŸ“„ test_seed_behavior.py
  ğŸ“„ test_sequence.py
  ğŸ“„ test_triton_utils.py
  ğŸ“„ test_version.py
  ğŸ“„ test_vllm_port.py
  ğŸ“ tokenization
  ğŸ“ tool_use
  ğŸ“ tools
  ğŸ“ tpu
  ğŸ“ transformers_utils
  ğŸ“„ utils.py
  ğŸ“ utils_
  ğŸ“ v1
  ğŸ“ vllm_test_utils
  ğŸ“ weight_loading
  ğŸ“„ check_repo.sh
  ğŸ“ ep_kernels
  ğŸ“„ flashinfer-build.sh
  ğŸ“„ generate_cmake_presets.py
  ğŸ“„ install_deepgemm.sh
  ğŸ“„ install_gdrcopy.sh
  ğŸ“„ install_nixl_from_source_ubuntu.py
  ğŸ“ pre_commit
  ğŸ“ profiler
  ğŸ“„ report_build_time_ninja.py
  ğŸ“ vllm-tpu
  ğŸ“„ __init__.py
  ğŸ“„ _bc_linter.py
  ğŸ“„ _custom_ops.py
  ğŸ“„ _ipex_ops.py
  ğŸ“ assets
  ğŸ“ attention
  ğŸ“„ beam_search.py
  ğŸ“ benchmarks
  ğŸ“„ collect_env.py
  ğŸ“ compilation
  ğŸ“ config
  ğŸ“„ connections.py
  ğŸ“ device_allocator
  ğŸ“ distributed
  ğŸ“ engine
  ğŸ“ entrypoints
  ğŸ“„ env_override.py
  ğŸ“„ envs.py
  ğŸ“„ forward_context.py
  ğŸ“ inputs
  ğŸ“„ logger.py
  ğŸ“ logging_utils
  ğŸ“„ logits_process.py
  ğŸ“„ logprobs.py
  ğŸ“ lora
  ğŸ“ model_executor
  ğŸ“ multimodal
  ğŸ“„ outputs.py
  ğŸ“ platforms
  ğŸ“ plugins
  ğŸ“„ pooling_params.py
  ğŸ“ profiler
  ğŸ“„ py.typed
  ğŸ“ ray
  ğŸ“ reasoning
  ğŸ“„ sampling_params.py
  ğŸ“„ scalar_type.py
  ğŸ“„ scripts.py
  ğŸ“„ sequence.py
  ğŸ“„ tasks.py
  ğŸ“ third_party
  ğŸ“„ tracing.py
  ğŸ“ transformers_utils
  ğŸ“ triton_utils
  ğŸ“ usage
  ğŸ“ utils
  ğŸ“ v1
  ğŸ“„ version.py
  ğŸ“ vllm_flash_attn
    ğŸ“ configs
    ğŸ“„ conftest.py
    ğŸ“„ run-lm-eval-chartqa-vllm-vlm-baseline.sh
    ğŸ“„ run-lm-eval-gsm-hf-baseline.sh
    ğŸ“„ run-lm-eval-gsm-vllm-baseline.sh
    ğŸ“„ run-lm-eval-mmlupro-vllm-baseline.sh
    ğŸ“„ test_lm_eval_correctness.py
    ğŸ“„ README.md
    ğŸ“„ performance-benchmarks-descriptions.md
    ğŸ“ scripts
    ğŸ“ tests
    ğŸ“„ annotate-release.sh
    ğŸ“„ ci-clean-log.sh
    ğŸ“„ cleanup-nightly-builds.sh
    ğŸ“ hardware_ci
    ğŸ“„ rerun-test.sh
    ğŸ“„ run-benchmarks.sh
    ğŸ“„ run-multi-node-test.sh
    ğŸ“„ run-prime-rl-test.sh
    ğŸ“ scheduled_integration_test
    ğŸ“ tpu
    ğŸ“„ upload-wheels.sh
    ğŸ“„ 100-documentation.yml
    ğŸ“„ 200-installation.yml
    ğŸ“„ 300-usage.yml
    ğŸ“„ 400-bug-report.yml
    ğŸ“„ 450-ci-failure.yml
    ğŸ“„ 500-feature-request.yml
    ğŸ“„ 600-new-model.yml
    ğŸ“„ 700-performance-discussion.yml
    ğŸ“„ 750-RFC.yml
    ğŸ“„ config.yml
    ğŸ“„ cleanup_pr_body.sh
    ğŸ“„ add_label_automerge.yml
    ğŸ“„ bc-lint.yml
    ğŸ“„ cleanup_pr_body.yml
    ğŸ“„ issue_autolabel.yml
    ğŸ“ matchers
    ğŸ“„ pre-commit.yml
    ğŸ“„ reminder_comment.yml
    ğŸ“ scripts
    ğŸ“„ stale.yml
    ğŸ“„ README.md
    ğŸ“„ auto_tune.sh
    ğŸ“„ batch_auto_tune.sh
    ğŸ“„ sparse_benchmarks.py
    ğŸ“„ utils.py
    ğŸ“„ w8a8_benchmarks.py
    ğŸ“„ weight_shapes.py
    ğŸ“„ disagg_overhead_benchmark.sh
    ğŸ“„ disagg_performance_benchmark.sh
    ğŸ“„ disagg_prefill_proxy_server.py
    ğŸ“„ rate_limiter.py
    ğŸ“„ request_queue.py
    ğŸ“„ round_robin_proxy.py
    ğŸ“„ visualize_benchmark_results.py
    ğŸ“„ layernorm_rms_benchmarks.py
    ğŸ“„ bench_block_fp8_gemm.py
    ğŸ“„ bench_fp8_gemm.py
    ğŸ“„ bench_int8_gemm.py
    ğŸ“„ bench_mxfp4_qutlass.py
    ğŸ“„ bench_nvfp4_gemm.py
    ğŸ“„ bench_nvfp4_qutlass.py
    ğŸ“„ bench_per_token_quant_fp8.py
    ğŸ“„ benchmark_activation.py
    ğŸ“„ benchmark_bitblas.py
    ğŸ“„ benchmark_cutlass_fp4_moe.py
    ğŸ“„ benchmark_cutlass_moe_fp8.py
    ğŸ“„ benchmark_device_communicators.py
    ğŸ“„ benchmark_grouped_gemm_cutlass.py
    ğŸ“„ benchmark_layernorm.py
    ğŸ“„ benchmark_lora.py
    ğŸ“„ benchmark_machete.py
    ğŸ“„ benchmark_marlin.py
    ğŸ“„ benchmark_moe.py
    ğŸ“„ benchmark_moe_align_block_size.py
    ğŸ“„ benchmark_moe_permute_unpermute.py
    ğŸ“„ benchmark_mrope.py
    ğŸ“„ benchmark_paged_attention.py
    ğŸ“„ benchmark_per_token_group_quant.py
    ğŸ“„ benchmark_quant.py
    ğŸ“„ benchmark_reshape_and_cache.py
    ğŸ“„ benchmark_reshape_and_cache_flash.py
    ğŸ“„ benchmark_rmsnorm.py
    ğŸ“„ benchmark_rope.py
    ğŸ“„ benchmark_shapes.py
    ğŸ“„ benchmark_silu_mul_fp8_quant.py
    ğŸ“„ benchmark_trtllm_decode_attention.py
    ğŸ“„ benchmark_trtllm_prefill_attention.py
    ğŸ“„ benchmark_w8a8_block_fp8.py
    ğŸ“ deepgemm
    ğŸ“„ graph_machete_bench.py
    ğŸ“„ requirements.txt
    ğŸ“„ utils.py
    ğŸ“„ weight_shapes.py
    ğŸ“„ README.md
    ğŸ“„ bench_dataset.py
    ğŸ“„ bench_utils.py
    ğŸ“„ benchmark_serving_multi_turn.py
    ğŸ“„ convert_sharegpt_to_openai.py
    ğŸ“„ generate_multi_turn.json
    ğŸ“„ requirements.txt
    ğŸ“„ benchmark_hashing.py
    ğŸ“„ structured_schema_1.json
    ğŸ“„ flashmla.cmake
    ğŸ“„ qutlass.cmake
    ğŸ“„ vllm_flash_attn.cmake
    ğŸ“„ attention_dtypes.h
    ğŸ“„ attention_generic.cuh
    ğŸ“„ attention_kernels.cuh
    ğŸ“„ attention_utils.cuh
    ğŸ“„ dtype_bfloat16.cuh
    ğŸ“„ dtype_float16.cuh
    ğŸ“„ dtype_float32.cuh
    ğŸ“„ dtype_fp8.cuh
    ğŸ“„ merge_attn_states.cu
    ğŸ“ mla
    ğŸ“„ paged_attention_v1.cu
    ğŸ“„ paged_attention_v2.cu
    ğŸ“„ vertical_slash_index.cu
    ğŸ“„ batch_invariant.hpp
    ğŸ“„ exception.hpp
    ğŸ“„ math.hpp
    ğŸ“„ registration.h
    ğŸ“„ scalar_type.hpp
    ğŸ“„ activation.cpp
    ğŸ“„ attention.cpp
    ğŸ“„ cache.cpp
    ğŸ“„ cpu_types.hpp
    ğŸ“„ cpu_types_arm.hpp
    ğŸ“„ cpu_types_scalar.hpp
    ğŸ“„ cpu_types_vsx.hpp
    ğŸ“„ cpu_types_vxe.hpp
    ğŸ“„ cpu_types_x86.hpp
    ğŸ“„ dnnl_helper.cpp
    ğŸ“„ dnnl_helper.h
    ğŸ“„ dnnl_kernels.cpp
    ğŸ“„ float_convert.hpp
    ğŸ“„ layernorm.cpp
    ğŸ“„ mla_decode.cpp
    ğŸ“„ pos_encoding.cpp
    ğŸ“ sgl-kernels
    ğŸ“„ shm.cpp
    ğŸ“„ torch_bindings.cpp
    ğŸ“„ utils.cpp
    ğŸ“„ common.cpp
    ğŸ“„ common.hpp
    ğŸ“„ cute_utils.cuh
    ğŸ“ epilogue
    ğŸ“„ torch_utils.hpp
    ğŸ“„ vllm_collective_builder.cuh
    ğŸ“„ vllm_custom_types.cuh
    ğŸ“„ vllm_cutlass_library_extension.py
    ğŸ“„ vllm_numeric_conversion.cuh
    ğŸ“„ vllm_type_utils.cuh
    ğŸ“ mamba_ssm
    ğŸ“„ dynamic_4bit_int_moe_cpu.cpp
    ğŸ“„ grouped_topk_kernels.cu
    ğŸ“ marlin_moe_wna16
    ğŸ“„ moe_align_sum_kernels.cu
    ğŸ“„ moe_lora_align_sum_kernels.cu
    ğŸ“„ moe_ops.h
    ğŸ“„ moe_permute_unpermute_op.cu
    ğŸ“„ moe_wna16.cu
    ğŸ“„ moe_wna16_utils.h
    ğŸ“ permute_unpermute_kernels
    ğŸ“„ topk_softmax_kernels.cu
    ğŸ“„ torch_bindings.cpp
    ğŸ“„ activation_kernels.cu
    ğŸ“ awq
    ğŸ“ cutlass_w4a8
    ğŸ“ fp4
    ğŸ“ fused_kernels
    ğŸ“ gguf
    ğŸ“ gptq
    ğŸ“ gptq_allspark
    ğŸ“ gptq_marlin
    ğŸ“ hadamard
    ğŸ“ machete
    ğŸ“ marlin
    ğŸ“„ utils.cuh
    ğŸ“„ vectorization.cuh
    ğŸ“„ vectorization_utils.cuh
    ğŸ“ w8a8
    ğŸ“„ base.h
    ğŸ“„ quick_reduce.h
    ğŸ“„ quick_reduce_impl.cuh
    ğŸ“„ attention.cu
    ğŸ“„ ops.h
    ğŸ“„ skinny_gemms.cu
    ğŸ“„ torch_bindings.cpp
    ğŸ“ cutlass
    ğŸ“„ README.md
    ğŸ“ vllm
    ğŸ“ contributing
    ğŸ“ deployment
    ğŸ“ design
    ğŸ“ features
    ğŸ“ logos
    ğŸ“„ .meta.yml
    ğŸ“„ .nav.yml
    ğŸ“„ README.md
    ğŸ“ bench
    ğŸ“„ chat.md
    ğŸ“„ complete.md
    ğŸ“„ json_tip.inc.md
    ğŸ“„ run-batch.md
    ğŸ“„ serve.md
    ğŸ“„ contact_us.md
    ğŸ“„ meetups.md
    ğŸ“„ sponsors.md
    ğŸ“„ README.md
    ğŸ“„ conserving_memory.md
    ğŸ“„ engine_args.md
    ğŸ“„ env_vars.md
    ğŸ“„ model_resolution.md
    ğŸ“„ optimization.md
    ğŸ“„ serve_args.md
    ğŸ“„ tpu.md
    ğŸ“„ README.md
    ğŸ“„ benchmarks.md
    ğŸ“ ci
    ğŸ“„ deprecation_policy.md
    ğŸ“ dockerfile
    ğŸ“„ incremental_build.md
    ğŸ“ model
    ğŸ“„ profiling.md
    ğŸ“„ vulnerability_management.md
    ğŸ“„ docker.md
    ğŸ“ frameworks
    ğŸ“ integrations
    ğŸ“„ k8s.md
    ğŸ“„ nginx.md
    ğŸ“„ arch_overview.md
    ğŸ“„ cuda_graphs.md
    ğŸ“„ dbo.md
    ğŸ“„ debug_vllm_compile.md
    ğŸ“„ fused_moe_modular_kernel.md
    ğŸ“„ huggingface_integration.md
    ğŸ“„ hybrid_kv_cache_manager.md
    ğŸ“„ io_processor_plugins.md
    ğŸ“„ logits_processors.md
    ğŸ“„ metrics.md
    ğŸ“„ mm_processing.md
    ğŸ“„ moe_kernel_features.md
    ğŸ“„ multiprocessing.md
    ğŸ“„ p2p_nccl_connector.md
    ğŸ“„ paged_attention.md
    ğŸ“„ plugin_system.md
    ğŸ“„ prefix_caching.md
    ğŸ“„ torch_compile.md
    ğŸ“„ README.md
    ğŸ“„ README.md
    ğŸ“„ automatic_prefix_caching.md
    ğŸ“„ batch_invariance.md
    ğŸ“„ custom_arguments.md
    ğŸ“„ custom_logitsprocs.md
    ğŸ“„ disagg_prefill.md
    ğŸ“„ lora.md
    ğŸ“„ multimodal_inputs.md
    ğŸ“„ nixl_connector_usage.md
    ğŸ“„ prompt_embeds.md
    ğŸ“ quantization
    ğŸ“„ reasoning_outputs.md
    ğŸ“„ sleep_mode.md
    ğŸ“„ spec_decode.md
    ğŸ“„ structured_outputs.md
    ğŸ“„ tool_calling.md
    ğŸ“ installation
    ğŸ“„ quickstart.md
    ğŸ“ hooks
    ğŸ“ javascript
    ğŸ“ overrides
    ğŸ“ stylesheets
    ğŸ“ extensions
    ğŸ“„ generative_models.md
    ğŸ“ hardware_supported_models
    ğŸ“„ pooling_models.md
    ğŸ“„ supported_models.md
    ğŸ“„ context_parallel_deployment.md
    ğŸ“„ data_parallel_deployment.md
    ğŸ“„ distributed_troubleshooting.md
    ğŸ“„ expert_parallel_deployment.md
    ğŸ“ integrations
    ğŸ“„ offline_inference.md
    ğŸ“„ openai_compatible_server.md
    ğŸ“„ parallelism_scaling.md
    ğŸ“„ rlhf.md
    ğŸ“„ trl.md
    ğŸ“„ README.md
    ğŸ“„ faq.md
    ğŸ“„ metrics.md
    ğŸ“„ reproducibility.md
    ğŸ“„ security.md
    ğŸ“„ troubleshooting.md
    ğŸ“„ usage_stats.md
    ğŸ“„ v1_guide.md
    ğŸ“„ async_llm_streaming.py
    ğŸ“„ audio_language.py
    ğŸ“„ automatic_prefix_caching.py
    ğŸ“ basic
    ğŸ“„ batch_llm_inference.py
    ğŸ“„ chat_with_tools.py
    ğŸ“„ context_extension.py
    ğŸ“„ data_parallel.py
    ğŸ“ disaggregated-prefill-v1
    ğŸ“„ disaggregated_prefill.py
    ğŸ“„ encoder_decoder_multimodal.py
    ğŸ“ kv_load_failure_recovery
    ğŸ“„ llm_engine_example.py
    ğŸ“„ load_sharded_state.py
    ğŸ“ logits_processor
    ğŸ“„ lora_with_quantization_inference.py
    ğŸ“„ metrics.py
    ğŸ“„ mistral-small.py
    ğŸ“„ mlpspeculator.py
    ğŸ“„ multilora_inference.py
    ğŸ“ openai_batch
    ğŸ“ pooling
    ğŸ“„ prefix_caching.py
    ğŸ“ profiling_tpu
    ğŸ“„ prompt_embed_inference.py
    ğŸ“ qwen2_5_omni
    ğŸ“„ qwen_1m.py
    ğŸ“„ reproducibility.py
    ğŸ“„ rlhf.py
    ğŸ“„ rlhf_colocate.py
    ğŸ“„ rlhf_utils.py
    ğŸ“„ save_sharded_state.py
    ğŸ“„ simple_profiling.py
    ğŸ“„ skip_loading_weights_in_engine_init.py
    ğŸ“„ spec_decode.py
    ğŸ“„ structured_outputs.py
    ğŸ“„ torchrun_dp_example.py
    ğŸ“„ torchrun_example.py
    ğŸ“„ tpu.py
    ğŸ“„ vision_language.py
    ğŸ“„ vision_language_multi_image.py
    ğŸ“„ vision_language_pooling.py
    ğŸ“„ api_client.py
    ğŸ“ chart-helm
    ğŸ“ dashboards
    ğŸ“„ disaggregated_prefill.sh
    ğŸ“ disaggregated_serving
    ğŸ“ disaggregated_serving_p2p_nccl_xpyd
    ğŸ“ elastic_ep
    ğŸ“„ gradio_openai_chatbot_webserver.py
    ğŸ“„ gradio_webserver.py
    ğŸ“„ kv_events_subscriber.py
    ğŸ“„ multi-node-serving.sh
    ğŸ“„ multi_instance_data_parallel.py
    ğŸ“„ openai_chat_completion_client.py
    ğŸ“„ openai_chat_completion_client_for_multimodal.py
    ğŸ“„ openai_chat_completion_client_with_tools.py
    ğŸ“„ openai_chat_completion_client_with_tools_required.py
    ğŸ“„ openai_chat_completion_client_with_tools_xlam.py
    ğŸ“„ openai_chat_completion_client_with_tools_xlam_streaming.py
    ğŸ“„ openai_chat_completion_tool_calls_with_reasoning.py
    ğŸ“„ openai_chat_completion_with_reasoning.py
    ğŸ“„ openai_chat_completion_with_reasoning_streaming.py
    ğŸ“„ openai_completion_client.py
    ğŸ“ openai_embedding_long_text
    ğŸ“„ openai_responses_client_with_tools.py
    ğŸ“„ openai_transcription_client.py
    ğŸ“„ openai_translation_client.py
    ğŸ“ opentelemetry
    ğŸ“ pooling
    ğŸ“ prometheus_grafana
    ğŸ“„ prompt_embed_inference_with_openai_client.py
    ğŸ“„ ray_serve_deepseek.py
    ğŸ“„ retrieval_augmented_generation_with_langchain.py
    ğŸ“„ retrieval_augmented_generation_with_llamaindex.py
    ğŸ“„ run_cluster.sh
    ğŸ“„ sagemaker-entrypoint.sh
    ğŸ“„ streamlit_openai_chatbot_webserver.py
    ğŸ“ structured_outputs
    ğŸ“„ utils.py
    ğŸ“ lmcache
    ğŸ“„ logging_configuration.md
    ğŸ“„ tensorize_vllm_model.py
    ğŸ“„ __init__.py
    ğŸ“„ test_basic_correctness.py
    ğŸ“„ test_cpu_offload.py
    ğŸ“„ test_cumem.py
    ğŸ“„ __init__.py
    ğŸ“„ test_latency_cli.py
    ğŸ“„ test_random_dataset.py
    ğŸ“„ test_random_multimodal_dataset_video.py
    ğŸ“„ test_serve_cli.py
    ğŸ“„ test_throughput_cli.py
    ğŸ“„ __init__.py
    ğŸ“„ backend.py
    ğŸ“ piecewise
    ğŸ“„ silly_attention.py
    ğŸ“„ test_aot_compile.py
    ğŸ“„ test_async_tp.py
    ğŸ“„ test_basic_correctness.py
    ğŸ“„ test_config.py
    ğŸ“„ test_decorator.py
    ğŸ“„ test_full_graph.py
    ğŸ“„ test_functionalization.py
    ğŸ“„ test_fusion.py
    ğŸ“„ test_fusion_all_reduce.py
    ğŸ“„ test_fusion_attn.py
    ğŸ“„ test_fusions_e2e.py
    ğŸ“„ test_multimodal_compile.py
    ğŸ“„ test_noop_elimination.py
    ğŸ“„ test_pass_manager.py
    ğŸ“„ test_sequence_parallelism.py
    ğŸ“„ test_silu_mul_quant_fusion.py
    ğŸ“„ test_wrapper.py
    ğŸ“„ test_config.yaml
    ğŸ“„ test_config_generation.py
    ğŸ“„ test_config_with_model.yaml
    ğŸ“„ test_mp_reducer.py
    ğŸ“„ test_multimodal_config.py
    ğŸ“„ test_cuda_context.py
    ğŸ“„ __init__.py
    ğŸ“„ test_disable_detokenization.py
    ğŸ“„ test_min_tokens.py
    ğŸ“„ test_stop_reason.py
    ğŸ“„ test_stop_string_while_stop_model_terminates.py
    ğŸ“„ test_stop_strings.py
    ğŸ“„ __init__.py
    ğŸ“„ conftest.py
    ğŸ“„ test_ca_buffer_sharing.py
    ğŸ“„ test_comm_ops.py
    ğŸ“„ test_context_parallel.py
    ğŸ“„ test_custom_all_reduce.py
    ğŸ“„ test_distributed_oot.py
    ğŸ“„ test_eplb_algo.py
    ğŸ“„ test_eplb_execute.py
    ğŸ“„ test_eplb_spec_decode.py
    ğŸ“„ test_events.py
    ğŸ“„ test_expert_parallel.py
    ğŸ“„ test_expert_placement.py
    ğŸ“„ test_kvlayout.py
    ğŸ“„ test_multi_node_assignment.py
    ğŸ“„ test_nccl_symm_mem_allreduce.py
    ğŸ“„ test_node_count.py
    ğŸ“„ test_pipeline_parallel.py
    ğŸ“„ test_pipeline_partition.py
    ğŸ“„ test_pp_cudagraph.py
    ğŸ“„ test_pynccl.py
    ğŸ“„ test_quick_all_reduce.py
    ğŸ“„ test_same_node.py
    ğŸ“„ test_sequence_parallel.py
    ğŸ“„ test_shm_broadcast.py
    ğŸ“„ test_shm_buffer.py
    ğŸ“„ test_shm_storage.py
    ğŸ“„ test_symm_mem_allreduce.py
    ğŸ“„ test_torchrun_example.py
    ğŸ“„ test_torchrun_example_moe.py
    ğŸ“„ test_utils.py
    ğŸ“„ __init__.py
    ğŸ“„ test_arg_utils.py
    ğŸ“„ test_short_mm_context.py
    ğŸ“„ __init__.py
    ğŸ“„ conftest.py
    ğŸ“ llm
    ğŸ“ offline_mode
    ğŸ“ openai
    ğŸ“ pooling
    ğŸ“„ test_api_server_process_manager.py
    ğŸ“„ test_chat_utils.py
    ğŸ“„ test_context.py
    ğŸ“„ test_harmony_utils.py
    ğŸ“„ test_renderer.py
    ğŸ“„ test_ssl_cert_refresher.py
    ğŸ“ gpt_oss
    ğŸ“ gsm8k
    ğŸ“„ __init__.py
    ğŸ“„ allclose_default.py
    ğŸ“ attention
    ğŸ“ core
    ğŸ“ mamba
    ğŸ“ moe
    ğŸ“„ quant_utils.py
    ğŸ“ quantization
    ğŸ“„ test_apply_repetition_penalties.py
    ğŸ“„ test_fla_layernorm_guard.py
    ğŸ“„ test_flex_attention.py
    ğŸ“„ test_fused_quant_activation.py
    ğŸ“„ test_onednn.py
    ğŸ“„ test_shuffle_rows.py
    ğŸ“„ test_top_k_per_row.py
    ğŸ“„ test_triton_flash_attention.py
    ğŸ“„ utils.py
    ğŸ“„ test_lookup_buffer.py
    ğŸ“„ test_lookup_buffer.sh
    ğŸ“„ test_module.py
    ğŸ“„ test_send_recv.py
    ğŸ“„ test_send_recv.sh
    ğŸ“„ __init__.py
    ğŸ“„ conftest.py
    ğŸ“„ test_add_lora.py
    ğŸ“„ test_chatglm3_tp.py
    ğŸ“„ test_deepseekv2_tp.py
    ğŸ“„ test_default_mm_loras.py
    ğŸ“„ test_fused_moe_lora_kernel.py
    ğŸ“„ test_gptoss_tp.py
    ğŸ“„ test_layers.py
    ğŸ“„ test_llama_tp.py
    ğŸ“„ test_llm_with_multi_loras.py
    ğŸ“„ test_lora_checkpoints.py
    ğŸ“„ test_lora_functions.py
    ğŸ“„ test_lora_huggingface.py
    ğŸ“„ test_lora_manager.py
    ğŸ“„ test_minicpmv_tp.py
    ğŸ“„ test_mixtral.py
    ğŸ“„ test_moe_lora_align_sum.py
    ğŸ“„ test_olmoe_tp.py
    ğŸ“„ test_peft_helper.py
    ğŸ“„ test_punica_ops.py
    ğŸ“„ test_quant_model.py
    ğŸ“„ test_qwen2vl.py
    ğŸ“„ test_qwen3moe_tp.py
    ğŸ“„ test_resolver.py
    ğŸ“„ test_transformers_model.py
    ğŸ“„ test_utils.py
    ğŸ“„ test_worker.py
    ğŸ“„ utils.py
    ğŸ“„ __init__.py
    ğŸ“ model_loader
    ğŸ“„ test_enabled_custom_ops.py
    ğŸ“„ test_model_load_with_params.py
    ğŸ“„ test_weight_utils.py
    ğŸ“„ __init__.py
    ğŸ“ fixtures
    ğŸ“ language
    ğŸ“ multimodal
    ğŸ“ quantization
    ğŸ“„ registry.py
    ğŸ“„ test_initialization.py
    ğŸ“„ test_oot_registration.py
    ğŸ“„ test_registry.py
    ğŸ“„ test_terratorch.py
    ğŸ“„ test_transformers.py
    ğŸ“„ test_utils.py
    ğŸ“„ test_vision.py
    ğŸ“„ utils.py
    ğŸ“„ __init__.py
    ğŸ“ assets
    ğŸ“„ test_audio.py
    ğŸ“„ test_cache.py
    ğŸ“„ test_hasher.py
    ğŸ“„ test_image.py
    ğŸ“„ test_inputs.py
    ğŸ“„ test_processing.py
    ğŸ“„ test_registry.py
    ğŸ“„ test_utils.py
    ğŸ“„ test_video.py
    ğŸ“„ utils.py
    ğŸ“ lora_resolvers
    ğŸ“ prithvi_io_processor_plugin
    ğŸ“ vllm_add_dummy_model
    ğŸ“ vllm_add_dummy_platform
    ğŸ“ vllm_add_dummy_stat_logger
    ğŸ“„ test_io_processor_plugins.py
    ğŸ“„ test_platform_plugins.py
    ğŸ“„ test_scheduler_plugins.py
    ğŸ“„ test_stats_logger_plugins.py
    ğŸ“„ example.txt
    ğŸ“„ summary.txt
    ğŸ“„ __init__.py
    ğŸ“„ fp_quant.py
    ğŸ“„ reference_mxfp4.py
    ğŸ“„ test_auto_round.py
    ğŸ“„ test_blackwell_moe.py
    ğŸ“„ test_compressed_tensors.py
    ğŸ“„ test_configs.py
    ğŸ“„ test_cpu_offload.py
    ğŸ“„ test_experts_int8.py
    ğŸ“„ test_fp8.py
    ğŸ“„ test_gptq_dynamic.py
    ğŸ“„ test_gptq_v2.py
    ğŸ“„ test_ipex_quant.py
    ğŸ“„ test_lm_head.py
    ğŸ“„ test_modelopt.py
    ğŸ“„ test_ptpc_fp8.py
    ğŸ“„ test_quark.py
    ğŸ“„ test_register_quantization_config.py
    ğŸ“„ test_rtn.py
    ğŸ“„ test_torchao.py
    ğŸ“„ utils.py
    ğŸ“„ __init__.py
    ğŸ“„ test_base_thinking_reasoning_parser.py
    ğŸ“„ test_deepseekr1_reasoning_parser.py
    ğŸ“„ test_deepseekv3_reasoning_parser.py
    ğŸ“„ test_ernie45_reasoning_parser.py
    ğŸ“„ test_glm4_moe_reasoning_parser.py
    ğŸ“„ test_granite_reasoning_parser.py
    ğŸ“„ test_hunyuan_reasoning_parser.py
    ğŸ“„ test_mistral_reasoning_parser.py
    ğŸ“„ test_olmo3_reasoning_parser.py
    ğŸ“„ test_qwen3_reasoning_parser.py
    ğŸ“„ test_seedoss_reasoning_parser.py
    ğŸ“„ utils.py
    ğŸ“„ __init__.py
    ğŸ“„ test_beam_search.py
    ğŸ“„ test_ignore_eos.py
    ğŸ“„ test_no_bad_words.py
    ğŸ“„ test_ranks.py
    ğŸ“„ lazy_imports.py
    ğŸ“„ python_only_compile.sh
    ğŸ“„ pytorch_nightly_dependency.sh
    ğŸ“„ sonnet3.5_nov2024.txt
    ğŸ“„ __init__.py
    ğŸ“„ test_cached_tokenizer.py
    ğŸ“„ test_detokenize.py
    ğŸ“„ test_do_lower_case.py
    ğŸ“„ test_get_eos.py
    ğŸ“„ test_mistral_tokenizer.py
    ğŸ“„ test_tokenizer.py
    ğŸ“„ test_tokenizer_registry.py
    ğŸ“„ __init__.py
    ğŸ“„ conftest.py
    ğŸ“ mistral
    ğŸ“„ test_chat_completion_request_validations.py
    ğŸ“„ test_chat_completions.py
    ğŸ“„ test_deepseekv31_tool_parser.py
    ğŸ“„ test_ernie45_moe_tool_parser.py
    ğŸ“„ test_glm4_moe_tool_parser.py
    ğŸ“„ test_jamba_tool_parser.py
    ğŸ“„ test_kimi_k2_tool_parser.py
    ğŸ“„ test_minimax_tool_parser.py
    ğŸ“„ test_openai_tool_parser.py
    ğŸ“„ test_parallel_tool_calls.py
    ğŸ“„ test_qwen3coder_tool_parser.py
    ğŸ“„ test_seed_oss_tool_parser.py
    ğŸ“„ test_tool_calls.py
    ğŸ“„ test_tool_choice_required.py
    ğŸ“„ test_xlam_tool_parser.py
    ğŸ“„ utils.py
    ğŸ“„ __init__.py
    ğŸ“„ test_config_validator.py
    ğŸ“„ __init__.py
    ğŸ“ lora
    ğŸ“„ test_compilation.py
    ğŸ“„ test_custom_dispatcher.py
    ğŸ“„ test_moe_pallas.py
    ğŸ“„ test_quantization_accuracy.py
    ğŸ“„ __init__.py
    ğŸ“„ test_config_parser_registry.py
    ğŸ“„ test_utils.py
    ğŸ“„ __init__.py
    ğŸ“„ test_argparse_utils.py
    ğŸ“„ test_async_utils.py
    ğŸ“„ test_cache.py
    ğŸ“„ test_collection_utils.py
    ğŸ“„ test_func_utils.py
    ğŸ“„ test_gc_utils.py
    ğŸ“„ test_hashing.py
    ğŸ“„ test_import_utils.py
    ğŸ“„ test_jsontree.py
    ğŸ“„ test_mem_utils.py
    ğŸ“„ test_network_utils.py
    ğŸ“„ test_serial_utils.py
    ğŸ“„ test_system_utils.py
    ğŸ“„ test_tensor_schema.py
    ğŸ“„ test_torch_utils.py
    ğŸ“„ __init__.py
    ğŸ“ attention
    ğŸ“ core
    ğŸ“ cudagraph
    ğŸ“ distributed
    ğŸ“ e2e
    ğŸ“ engine
    ğŸ“ entrypoints
    ğŸ“ executor
    ğŸ“ generation
    ğŸ“ kv_connector
    ğŸ“ kv_offload
    ğŸ“ logits_processors
    ğŸ“ metrics
    ğŸ“ sample
    ğŸ“ shutdown
    ğŸ“ spec_decode
    ğŸ“ structured_output
    ğŸ“„ test_oracle.py
    ğŸ“„ test_request.py
    ğŸ“„ test_serial_utils.py
    ğŸ“ tpu
    ğŸ“ tracing
    ğŸ“„ utils.py
    ğŸ“ worker
    ğŸ“„ setup.py
    ğŸ“ vllm_test_utils
    ğŸ“„ models-large.txt
    ğŸ“„ models.txt
    ğŸ“„ run_model_weight_loading_test.sh
    ğŸ“„ test_weight_loading.py
    ğŸ“„ README.md
    ğŸ“„ configure_system_drivers.sh
    ğŸ“ elastic_ep
    ğŸ“„ install_python_libraries.sh
    ğŸ“„ check_init_lazy_imports.py
    ğŸ“„ check_pickle_imports.py
    ğŸ“„ check_spdx_header.py
    ğŸ“„ check_triton_import.py
    ğŸ“„ enforce_regex_import.py
    ğŸ“„ generate_nightly_torch_test.py
    ğŸ“„ mypy.py
    ğŸ“„ png-lint.sh
    ğŸ“„ shellcheck.sh
    ğŸ“„ update-dockerfile-graph.sh
    ğŸ“„ validate_config.py
    ğŸ“ nsys_profile_tools
    ğŸ“„ print_layerwise_table.py
    ğŸ“„ visualize_layerwise_profile.py
    ğŸ“„ build.sh
    ğŸ“„ __init__.py
    ğŸ“„ audio.py
    ğŸ“„ base.py
    ğŸ“„ image.py
    ğŸ“„ video.py
    ğŸ“„ __init__.py
    ğŸ“ backends
    ğŸ“„ layer.py
    ğŸ“ layers
    ğŸ“ ops
    ğŸ“„ selector.py
    ğŸ“ utils
    ğŸ“„ __init__.py
    ğŸ“„ datasets.py
    ğŸ“„ latency.py
    ğŸ“ lib
    ğŸ“„ serve.py
    ğŸ“ sweep
    ğŸ“„ throughput.py
    ğŸ“„ __init__.py
    ğŸ“„ activation_quant_fusion.py
    ğŸ“„ backends.py
    ğŸ“„ base_static_graph.py
    ğŸ“„ caching.py
    ğŸ“„ collective_fusion.py
    ğŸ“„ compiler_interface.py
    ğŸ“„ counter.py
    ğŸ“„ cuda_graph.py
    ğŸ“„ decorators.py
    ğŸ“„ fix_functionalization.py
    ğŸ“„ fusion.py
    ğŸ“„ fusion_attn.py
    ğŸ“„ fx_utils.py
    ğŸ“„ inductor_pass.py
    ğŸ“„ matcher_utils.py
    ğŸ“„ monitor.py
    ğŸ“„ noop_elimination.py
    ğŸ“„ partition_rules.py
    ğŸ“„ pass_manager.py
    ğŸ“„ piecewise_backend.py
    ğŸ“„ post_cleanup.py
    ğŸ“„ sequence_parallelism.py
    ğŸ“„ torch25_custom_graph_pass.py
    ğŸ“„ vllm_inductor_pass.py
    ğŸ“„ wrapper.py
    ğŸ“„ __init__.py
    ğŸ“„ cache.py
    ğŸ“„ compilation.py
    ğŸ“„ device.py
    ğŸ“„ kv_events.py
    ğŸ“„ kv_transfer.py
    ğŸ“„ load.py
    ğŸ“„ lora.py
    ğŸ“„ model.py
    ğŸ“„ multimodal.py
    ğŸ“„ observability.py
    ğŸ“„ parallel.py
    ğŸ“„ pooler.py
    ğŸ“„ scheduler.py
    ğŸ“„ speculative.py
    ğŸ“„ speech_to_text.py
    ğŸ“„ structured_outputs.py
    ğŸ“„ utils.py
    ğŸ“„ vllm.py
    ğŸ“„ __init__.py
    ğŸ“„ cumem.py
    ğŸ“„ __init__.py
    ğŸ“„ communication_op.py
    ğŸ“ device_communicators
    ğŸ“ eplb
    ğŸ“„ kv_events.py
    ğŸ“ kv_transfer
    ğŸ“„ parallel_state.py
    ğŸ“„ tpu_distributed_utils.py
    ğŸ“„ utils.py
    ğŸ“„ __init__.py
    ğŸ“„ arg_utils.py
    ğŸ“„ async_llm_engine.py
    ğŸ“„ llm_engine.py
    ğŸ“„ protocol.py
    ğŸ“„ __init__.py
    ğŸ“ anthropic
    ğŸ“„ api_server.py
    ğŸ“„ chat_utils.py
    ğŸ“ cli
    ğŸ“„ constants.py
    ğŸ“„ context.py
    ğŸ“„ harmony_utils.py
    ğŸ“„ launcher.py
    ğŸ“„ llm.py
    ğŸ“„ logger.py
    ğŸ“ openai
    ğŸ“„ renderer.py
    ğŸ“„ responses_utils.py
    ğŸ“„ score_utils.py
    ğŸ“„ ssl.py
    ğŸ“„ tool.py
    ğŸ“„ tool_server.py
    ğŸ“„ utils.py
    ğŸ“„ __init__.py
    ğŸ“„ data.py
    ğŸ“„ parse.py
    ğŸ“„ preprocess.py
    ğŸ“„ __init__.py
    ğŸ“„ dump_input.py
    ğŸ“„ formatter.py
    ğŸ“„ log_time.py
    ğŸ“„ __init__.py
    ğŸ“ layers
    ğŸ“„ lora_weights.py
    ğŸ“„ models.py
    ğŸ“ ops
    ğŸ“„ peft_helper.py
    ğŸ“ punica_wrapper
    ğŸ“„ request.py
    ğŸ“„ resolver.py
    ğŸ“„ utils.py
    ğŸ“„ worker_manager.py
    ğŸ“„ __init__.py
    ğŸ“„ custom_op.py
    ğŸ“ layers
    ğŸ“ model_loader
    ğŸ“ models
    ğŸ“„ parameter.py
    ğŸ“„ utils.py
    ğŸ“ warmup
    ğŸ“„ __init__.py
    ğŸ“„ audio.py
    ğŸ“„ base.py
    ğŸ“„ cache.py
    ğŸ“„ evs.py
    ğŸ“„ hasher.py
    ğŸ“„ image.py
    ğŸ“„ inputs.py
    ğŸ“„ parse.py
    ğŸ“„ processing.py
    ğŸ“„ profiling.py
    ğŸ“„ registry.py
    ğŸ“„ utils.py
    ğŸ“„ video.py
    ğŸ“„ __init__.py
    ğŸ“„ cpu.py
    ğŸ“„ cuda.py
    ğŸ“„ interface.py
    ğŸ“„ rocm.py
    ğŸ“„ tpu.py
    ğŸ“„ xpu.py
    ğŸ“„ __init__.py
    ğŸ“ io_processors
    ğŸ“ lora_resolvers
    ğŸ“„ __init__.py
    ğŸ“„ layerwise_profile.py
    ğŸ“„ utils.py
    ğŸ“„ __init__.py
    ğŸ“„ lazy_utils.py
    ğŸ“„ ray_env.py
    ğŸ“„ __init__.py
    ğŸ“„ abs_reasoning_parsers.py
    ğŸ“„ basic_parsers.py
    ğŸ“„ deepseek_r1_reasoning_parser.py
    ğŸ“„ deepseek_v3_reasoning_parser.py
    ğŸ“„ ernie45_reasoning_parser.py
    ğŸ“„ glm4_moe_reasoning_parser.py
    ğŸ“„ gptoss_reasoning_parser.py
    ğŸ“„ granite_reasoning_parser.py
    ğŸ“„ hunyuan_a13b_reasoning_parser.py
    ğŸ“„ identity_reasoning_parser.py
    ğŸ“„ minimax_m2_reasoning_parser.py
    ğŸ“„ mistral_reasoning_parser.py
    ğŸ“„ olmo3_reasoning_parser.py
    ğŸ“„ qwen3_reasoning_parser.py
    ğŸ“„ seedoss_reasoning_parser.py
    ğŸ“„ step3_reasoning_parser.py
    ğŸ“„ __init__.py
    ğŸ“„ pynvml.py
    ğŸ“„ __init__.py
    ğŸ“ chat_templates
    ğŸ“„ config.py
    ğŸ“„ config_parser_base.py
    ğŸ“ configs
    ğŸ“„ detokenizer_utils.py
    ğŸ“„ dynamic_module.py
    ğŸ“„ processor.py
    ğŸ“ processors
    ğŸ“„ runai_utils.py
    ğŸ“„ s3_utils.py
    ğŸ“„ tokenizer.py
    ğŸ“„ tokenizer_base.py
    ğŸ“ tokenizers
    ğŸ“„ utils.py
    ğŸ“„ __init__.py
    ğŸ“„ importing.py
    ğŸ“„ __init__.py
    ğŸ“„ usage_lib.py
    ğŸ“„ __init__.py
    ğŸ“„ argparse_utils.py
    ğŸ“„ async_utils.py
    ğŸ“„ cache.py
    ğŸ“„ collection_utils.py
    ğŸ“„ counter.py
    ğŸ“„ deep_gemm.py
    ğŸ“„ flashinfer.py
    ğŸ“„ func_utils.py
    ğŸ“„ gc_utils.py
    ğŸ“„ hashing.py
    ğŸ“„ import_utils.py
    ğŸ“„ jsontree.py
    ğŸ“„ math_utils.py
    ğŸ“„ mem_constants.py
    ğŸ“„ mem_utils.py
    ğŸ“„ nccl.py
    ğŸ“„ network_utils.py
    ğŸ“„ platform_utils.py
    ğŸ“„ profiling.py
    ğŸ“„ registry.py
    ğŸ“„ serial_utils.py
    ğŸ“„ system_utils.py
    ğŸ“„ tensor_schema.py
    ğŸ“„ torch_utils.py
    ğŸ“„ __init__.py
    ğŸ“ attention
    ğŸ“ core
    ğŸ“„ cudagraph_dispatcher.py
    ğŸ“ engine
    ğŸ“ executor
    ğŸ“„ kv_cache_interface.py
    ğŸ“ kv_offload
    ğŸ“ metrics
    ğŸ“„ outputs.py
    ğŸ“ pool
    ğŸ“„ request.py
    ğŸ“ sample
    ğŸ“„ serial_utils.py
    ğŸ“ spec_decode
    ğŸ“ structured_output
    ğŸ“„ utils.py
    ğŸ“ worker
    ğŸ“„ .gitkeep
      ğŸ“„ DeepSeek-V2-Lite-Chat.yaml
      ğŸ“„ Meta-Llama-3-70B-Instruct-FBGEMM-nonuniform.yaml
      ğŸ“„ Meta-Llama-3-70B-Instruct.yaml
      ğŸ“„ Meta-Llama-3-8B-Instruct-Channelwise-compressed-tensors.yaml
      ğŸ“„ Meta-Llama-3-8B-Instruct-FBGEMM-nonuniform.yaml
      ğŸ“„ Meta-Llama-3-8B-Instruct-FP8-compressed-tensors.yaml
      ğŸ“„ Meta-Llama-3-8B-Instruct-FP8.yaml
      ğŸ“„ Meta-Llama-3-8B-Instruct-INT8-compressed-tensors-asym.yaml
      ğŸ“„ Meta-Llama-3-8B-Instruct-INT8-compressed-tensors.yaml
      ğŸ“„ Meta-Llama-3-8B-Instruct-nonuniform-compressed-tensors.yaml
      ğŸ“„ Meta-Llama-3-8B-Instruct.yaml
      ğŸ“„ Meta-Llama-3-8B-QQQ.yaml
      ğŸ“„ Meta-Llama-3.2-1B-Instruct-FP8-compressed-tensors.yaml
      ğŸ“„ Meta-Llama-3.2-1B-Instruct-INT8-compressed-tensors.yaml
      ğŸ“„ Meta-Llama-4-Maverick-17B-128E-Instruct-FP8-MM.yaml
      ğŸ“„ Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.yaml
      ğŸ“„ Minitron-4B-Base-FP8.yaml
      ğŸ“„ Mixtral-8x22B-Instruct-v0.1-FP8-Dynamic.yaml
      ğŸ“„ Mixtral-8x7B-Instruct-v0.1-FP8.yaml
      ğŸ“„ Mixtral-8x7B-Instruct-v0.1.yaml
      ğŸ“„ Qwen1.5-MoE-W4A16-compressed-tensors.yaml
      ğŸ“„ Qwen2-1.5B-Instruct-FP8W8.yaml
      ğŸ“„ Qwen2-1.5B-Instruct-INT8-compressed-tensors.yaml
      ğŸ“„ Qwen2-1.5B-Instruct-W8A16-compressed-tensors.yaml
      ğŸ“„ Qwen2-57B-A14-Instruct.yaml
      ğŸ“„ Qwen2.5-1.5B-Instruct.yaml
      ğŸ“„ Qwen2.5-VL-3B-Instruct-FP8-dynamic.yaml
      ğŸ“„ Qwen2.5-VL-7B-Instruct.yaml
      ğŸ“„ Qwen3-235B-A22B-Instruct-2507-FP8.yaml
      ğŸ“„ SparseLlama3.1_2of4_fp8_compressed.yaml
      ğŸ“„ models-large-hopper.txt
      ğŸ“„ models-large.txt
      ğŸ“„ models-mm-large-h100.txt
      ğŸ“„ models-mm-small.txt
      ğŸ“„ models-small.txt
      ğŸ“„ compare-json-results.py
      ğŸ“„ convert-results-json-to-markdown.py
      ğŸ“„ launch-server.sh
      ğŸ“„ run-performance-benchmarks.sh
      ğŸ“„ genai-perf-tests.json
      ğŸ“„ latency-tests-cpu.json
      ğŸ“„ latency-tests-hpu.json
      ğŸ“„ latency-tests.json
      ğŸ“„ nightly-tests.json
      ğŸ“„ serving-tests-cpu-snc2.json
      ğŸ“„ serving-tests-cpu-snc3.json
      ğŸ“„ serving-tests-cpu.json
      ğŸ“„ serving-tests-hpu.json
      ğŸ“„ serving-tests.json
      ğŸ“„ throughput-tests-cpu.json
      ğŸ“„ throughput-tests-hpu.json
      ğŸ“„ throughput-tests.json
      ğŸ“„ run-amd-test.sh
      ğŸ“„ run-cpu-test-ppc64le.sh
      ğŸ“„ run-cpu-test-s390x.sh
      ğŸ“„ run-cpu-test.sh
      ğŸ“„ run-gh200-test.sh
      ğŸ“„ run-hpu-test.sh
      ğŸ“„ run-npu-test.sh
      ğŸ“„ run-tpu-v1-test-part2.sh
      ğŸ“„ run-tpu-v1-test.sh
      ğŸ“„ run-xpu-test.sh
      ğŸ“„ deepseek_v2_lite_ep_eplb.sh
      ğŸ“„ qwen30b_a3b_fp8_block_ep.sh
      ğŸ“„ cleanup_docker.sh
      ğŸ“„ config_v6e_1.env
      ğŸ“„ docker_run_bm.sh
      ğŸ“„ quantized_v6e_1.env
      ğŸ“„ run_bm.sh
      ğŸ“„ actionlint.json
      ğŸ“„ markdownlint.json
      ğŸ“„ mypy.json
      ğŸ“„ build.sh
      ğŸ“„ create_release.js
      ğŸ“„ cuda-install.sh
      ğŸ“„ env.sh
      ğŸ“„ pytorch-install.sh
      ğŸ“„ README.md
      ğŸ“„ benchmark_fp8_block_dense_gemm.py
      ğŸ“ cutlass_sm100_mla
      ğŸ“„ sm100_cutlass_mla_kernel.cu
      ğŸ“„ common.h
      ğŸ“„ gemm.cpp
      ğŸ“„ gemm.h
      ğŸ“„ gemm_fp8.cpp
      ğŸ“„ gemm_int8.cpp
      ğŸ“„ moe.cpp
      ğŸ“„ moe_fp8.cpp
      ğŸ“„ moe_int8.cpp
      ğŸ“„ vec.h
      ğŸ“„ broadcast_load_epilogue_array_c3x.hpp
      ğŸ“„ broadcast_load_epilogue_c2x.hpp
      ğŸ“„ broadcast_load_epilogue_c3x.hpp
      ğŸ“„ scaled_mm_epilogues_c2x.hpp
      ğŸ“„ scaled_mm_epilogues_c3x.hpp
      ğŸ“„ selective_scan.h
      ğŸ“„ selective_scan_fwd.cu
      ğŸ“„ static_switch.h
      ğŸ“„ .gitignore
      ğŸ“„ generate_kernels.py
      ğŸ“„ kernel.h
      ğŸ“„ marlin_template.h
      ğŸ“„ ops.cu
      ğŸ“„ dispatch.h
      ğŸ“„ moe_permute_unpermute_kernel.cu
      ğŸ“„ moe_permute_unpermute_kernel.h
      ğŸ“„ moe_permute_unpermute_kernel.inl
      ğŸ“„ dequantize.cuh
      ğŸ“„ gemm_kernels.cu
      ğŸ“„ w4a8_mm_entry.cu
      ğŸ“„ activation_nvfp4_quant_fusion_kernels.cu
      ğŸ“„ nvfp4_blockwise_moe_kernel.cu
      ğŸ“„ nvfp4_experts_quant.cu
      ğŸ“„ nvfp4_quant_entry.cu
      ğŸ“„ nvfp4_quant_kernels.cu
      ğŸ“„ nvfp4_scaled_mm_entry.cu
      ğŸ“„ nvfp4_scaled_mm_kernels.cu
      ğŸ“„ nvfp4_scaled_mm_sm120_kernels.cu
      ğŸ“„ nvfp4_utils.cuh
      ğŸ“„ fused_layernorm_dynamic_per_token_quant.cu
      ğŸ“„ layernorm_utils.cuh
      ğŸ“„ quant_conversions.cuh
      ğŸ“„ dequantize.cuh
      ğŸ“„ ggml-common.h
      ğŸ“„ gguf_kernel.cu
      ğŸ“„ mmq.cuh
      ğŸ“„ mmvq.cuh
      ğŸ“„ moe.cuh
      ğŸ“„ moe_vec.cuh
      ğŸ“„ vecdotq.cuh
      ğŸ“„ compat.cuh
      ğŸ“„ matrix_view.cuh
      ğŸ“„ q_gemm.cu
      ğŸ“„ qdq_2.cuh
      ğŸ“„ qdq_3.cuh
      ğŸ“„ qdq_4.cuh
      ğŸ“„ qdq_8.cuh
      ğŸ“„ qdq_util.cuh
      ğŸ“„ allspark_qgemm_w8a16.cu
      ğŸ“„ allspark_repack.cu
      ğŸ“„ allspark_utils.cuh
      ğŸ“„ .gitignore
      ğŸ“„ awq_marlin_repack.cu
      ğŸ“„ dequant.h
      ğŸ“„ generate_kernels.py
      ğŸ“„ gptq_marlin.cu
      ğŸ“„ gptq_marlin_repack.cu
      ğŸ“„ kernel.h
      ğŸ“„ marlin.cuh
      ğŸ“„ marlin_dtypes.cuh
      ğŸ“„ marlin_template.h
      ğŸ“ hadacore
      ğŸ“„ Readme.md
      ğŸ“„ generate.py
      ğŸ“„ machete_collective_builder.cuh
      ğŸ“„ machete_interleaving_utils.cuh
      ğŸ“„ machete_mainloop.cuh
      ğŸ“„ machete_mm_kernel.cuh
      ğŸ“„ machete_mm_launcher.cuh
      ğŸ“„ machete_prepack_kernel.cuh
      ğŸ“„ machete_prepack_launcher.cuh
      ğŸ“„ machete_prepacked_layout.cuh
      ğŸ“„ machete_pytorch.cu
      ğŸ“ sparse
      ğŸ“ cutlass
      ğŸ“ fp8
      ğŸ“ int8
      ğŸ“„ per_token_group_quant_8bit.h
      ğŸ“„ sparse_compressor_c3x.cuh
      ğŸ“„ sparse_scaled_mm_c3x.cu
      ğŸ“„ sparse_scaled_mm_c3x.cuh
      ğŸ“„ sparse_scaled_mm_entry.cu
      ğŸ“„ .meta.yml
      ğŸ“„ dockerfile-stages-dependency.png
      ğŸ“„ load-pattern-examples.png
      ğŸ“„ anything-llm-chat-with-doc.png
      ğŸ“„ anything-llm-chat-without-doc.png
      ğŸ“„ anything-llm-provider.png
      ğŸ“„ anything-llm-upload-doc.png
      ğŸ“„ architecture_helm_deployment.png
      ğŸ“„ chatbox-chat.png
      ğŸ“„ chatbox-settings.png
      ğŸ“„ dify-chat.png
      ğŸ“„ dify-create-chatbot.png
      ğŸ“„ dify-settings.png
      ğŸ“„ dp_external_lb.png
      ğŸ“„ dp_internal_lb.png
      ğŸ“„ hf-inference-endpoints-catalog.png
      ğŸ“„ hf-inference-endpoints-choose-infra.png
      ğŸ“„ hf-inference-endpoints-click-deploy-button.png
      ğŸ“„ hf-inference-endpoints-configure-container.png
      ğŸ“„ hf-inference-endpoints-create-endpoint.png
      ğŸ“„ hf-inference-endpoints-locate-deploy-button.png
      ğŸ“„ hf-inference-endpoints-new-endpoint.png
      ğŸ“„ hf-inference-endpoints-select-hardware.png
      ğŸ“„ hf-inference-endpoints-select-model.png
      ğŸ“„ open_webui.png
      ğŸ“„ streamlit-chat.png
      ğŸ“ arch_overview
      ğŸ“ cuda_graphs
      ğŸ“ debug_vllm_compile
      ğŸ“ fused_moe_modular_kernel
      ğŸ“„ hierarchy.png
      ğŸ“ hybrid_kv_cache_manager
      ğŸ“ metrics
      ğŸ“ paged_attention
      ğŸ“ prefix_caching
      ğŸ“ tpu
      ğŸ“ disagg_prefill
      ğŸ“„ vllm-logo-only-light.ico
      ğŸ“„ vllm-logo-only-light.png
      ğŸ“„ vllm-logo-text-dark.png
      ğŸ“„ vllm-logo-text-light.png
      ğŸ“„ latency.md
      ğŸ“„ serve.md
      ğŸ“ sweep
      ğŸ“„ throughput.md
      ğŸ“„ failures.md
      ğŸ“„ update_pytorch_version.md
      ğŸ“„ dockerfile.md
      ğŸ“„ README.md
      ğŸ“„ basic.md
      ğŸ“„ multimodal.md
      ğŸ“„ registration.md
      ğŸ“„ tests.md
      ğŸ“„ transcription.md
      ğŸ“„ anyscale.md
      ğŸ“„ anything-llm.md
      ğŸ“„ autogen.md
      ğŸ“„ bentoml.md
      ğŸ“„ cerebrium.md
      ğŸ“„ chatbox.md
      ğŸ“„ dify.md
      ğŸ“„ dstack.md
      ğŸ“„ haystack.md
      ğŸ“„ helm.md
      ğŸ“„ hf_inference_endpoints.md
      ğŸ“„ litellm.md
      ğŸ“„ lobe-chat.md
      ğŸ“„ lws.md
      ğŸ“„ modal.md
      ğŸ“„ open-webui.md
      ğŸ“„ retrieval_augmented_generation.md
      ğŸ“„ skypilot.md
      ğŸ“„ streamlit.md
      ğŸ“„ triton.md
      ğŸ“„ kaito.md
      ğŸ“„ kserve.md
      ğŸ“„ kubeai.md
      ğŸ“„ kuberay.md
      ğŸ“„ llamastack.md
      ğŸ“„ llmaz.md
      ğŸ“„ production-stack.md
      ğŸ“„ README.md
      ğŸ“„ auto_awq.md
      ğŸ“„ auto_round.md
      ğŸ“„ bitblas.md
      ğŸ“„ bnb.md
      ğŸ“„ fp8.md
      ğŸ“„ gguf.md
      ğŸ“„ gptqmodel.md
      ğŸ“„ inc.md
      ğŸ“„ int4.md
      ğŸ“„ int8.md
      ğŸ“„ modelopt.md
      ğŸ“„ quantized_kvcache.md
      ğŸ“„ quark.md
      ğŸ“„ torchao.md
      ğŸ“„ .nav.yml
      ğŸ“„ README.md
      ğŸ“„ cpu.apple.inc.md
      ğŸ“„ cpu.arm.inc.md
      ğŸ“„ cpu.md
      ğŸ“„ cpu.s390x.inc.md
      ğŸ“„ cpu.x86.inc.md
      ğŸ“„ device.template.md
      ğŸ“„ gpu.cuda.inc.md
      ğŸ“„ gpu.md
      ğŸ“„ gpu.rocm.inc.md
      ğŸ“„ gpu.xpu.inc.md
      ğŸ“„ python_env_setup.inc.md
      ğŸ“„ generate_argparse.py
      ğŸ“„ generate_examples.py
      ğŸ“„ remove_announcement.py
      ğŸ“„ url_schemes.py
      ğŸ“„ edit_and_feedback.js
      ğŸ“„ mathjax.js
      ğŸ“„ run_llm_widget.js
      ğŸ“„ slack_and_forum.js
      ğŸ“„ main.html
      ğŸ“ partials
      ğŸ“„ extra.css
      ğŸ“„ fastsafetensor.md
      ğŸ“„ runai_model_streamer.md
      ğŸ“„ tensorizer.md
      ğŸ“„ tpu.md
      ğŸ“„ langchain.md
      ğŸ“„ llamaindex.md
      ğŸ“„ README.md
      ğŸ“„ basic.py
      ğŸ“„ chat.py
      ğŸ“„ classify.py
      ğŸ“„ embed.py
      ğŸ“„ generate.py
      ğŸ“„ reward.py
      ğŸ“„ score.py
      ğŸ“„ README.md
      ğŸ“„ decode_example.py
      ğŸ“„ prefill_example.py
      ğŸ“„ run.sh
      ğŸ“„ README.md
      ğŸ“„ decode_example.py
      ğŸ“„ prefill_example.py
      ğŸ“„ rogue_shared_storage_connector.py
      ğŸ“„ run.sh
      ğŸ“„ custom.py
      ğŸ“„ custom_req.py
      ğŸ“„ custom_req_init.py
      ğŸ“„ README.md
      ğŸ“„ openai_example_batch.jsonl
      ğŸ“„ README.md
      ğŸ“„ convert_model_to_seq_cls.py
      ğŸ“„ embed_jina_embeddings_v3.py
      ğŸ“„ embed_matryoshka_fy.py
      ğŸ“„ multi_vector_retrieval.py
      ğŸ“„ ner.py
      ğŸ“„ prithvi_geospatial_mae.py
      ğŸ“„ prithvi_geospatial_mae_io_processor.py
      ğŸ“„ qwen3_reranker.py
      ğŸ“„ README.md
      ğŸ“„ profiling.py
      ğŸ“„ README.md
      ğŸ“„ only_thinker.py
      ğŸ“„ .helmignore
      ğŸ“„ Chart.yaml
      ğŸ“„ README.md
      ğŸ“„ ct.yaml
      ğŸ“„ lintconf.yaml
      ğŸ“ templates
      ğŸ“„ values.schema.json
      ğŸ“„ values.yaml
      ğŸ“„ README.md
      ğŸ“ grafana
      ğŸ“ perses
      ğŸ“„ README.md
      ğŸ“„ disagg_proxy_demo.py
      ğŸ“„ kv_events.sh
      ğŸ“„ disagg_example_p2p_nccl_xpyd.sh
      ğŸ“„ disagg_proxy_p2p_nccl_xpyd.py
      ğŸ“„ bench.sh
      ğŸ“„ scale.py
      ğŸ“„ serve_deepseek_v2.sh
      ğŸ“„ README.md
      ğŸ“„ client.py
      ğŸ“„ service.sh
      ğŸ“„ README.md
      ğŸ“„ dummy_client.py
      ğŸ“„ README.md
      ğŸ“„ cohere_rerank_client.py
      ğŸ“„ embedding_requests_base64_client.py
      ğŸ“„ embedding_requests_bytes_client.py
      ğŸ“„ jinaai_rerank_client.py
      ğŸ“„ multi_vector_retrieval_client.py
      ğŸ“„ ner_client.py
      ğŸ“„ openai_chat_embedding_client_for_multimodal.py
      ğŸ“„ openai_classification_client.py
      ğŸ“„ openai_cross_encoder_score.py
      ğŸ“„ openai_cross_encoder_score_for_multimodal.py
      ğŸ“„ openai_embedding_client.py
      ğŸ“„ openai_embedding_matryoshka_fy.py
      ğŸ“„ openai_pooling_client.py
      ğŸ“„ prithvi_geospatial_mae.py
      ğŸ“„ README.md
      ğŸ“„ docker-compose.yaml
      ğŸ“„ grafana.json
      ğŸ“„ prometheus.yaml
      ğŸ“„ README.md
      ğŸ“„ pyproject.toml
      ğŸ“„ structured_outputs.py
      ğŸ“„ README.md
      ğŸ“„ cpu_offload_lmcache.py
      ğŸ“„ disagg_prefill_lmcache_v0.py
      ğŸ“ disagg_prefill_lmcache_v1
      ğŸ“„ kv_cache_sharing_lmcache_v1.py
      ğŸ“„ __init__.py
      ğŸ“„ test_full_cudagraph.py
      ğŸ“„ test_multiple_graphs.py
      ğŸ“„ test_simple.py
      ğŸ“„ test_toy_llama.py
      ğŸ“„ __init__.py
      ğŸ“„ test_accuracy.py
      ğŸ“„ test_chat.py
      ğŸ“„ test_collective_rpc.py
      ğŸ“„ test_generate.py
      ğŸ“„ test_gpu_utilization.py
      ğŸ“„ test_mm_cache_stats.py
      ğŸ“„ test_prompt_validation.py
      ğŸ“„ __init__.py
      ğŸ“„ test_offline_mode.py
      ğŸ“„ __init__.py
      ğŸ“„ conftest.py
      ğŸ“ correctness
      ğŸ“„ test_async_tokenization.py
      ğŸ“„ test_audio.py
      ğŸ“„ test_basic.py
      ğŸ“„ test_chat.py
      ğŸ“„ test_chat_echo.py
      ğŸ“„ test_chat_logit_bias_validation.py
      ğŸ“„ test_chat_template.py
      ğŸ“„ test_chat_with_tool_reasoning.py
      ğŸ“„ test_chunked_prompt.py
      ğŸ“„ test_cli_args.py
      ğŸ“„ test_collective_rpc.py
      ğŸ“„ test_completion_with_function_calling.py
      ğŸ“„ test_completion_with_prompt_embeds.py
      ğŸ“„ test_default_mm_loras.py
      ğŸ“„ test_enable_force_include_usage.py
      ğŸ“„ test_gptoss_structural_tags_integration.py
      ğŸ“„ test_lora_adapters.py
      ğŸ“„ test_lora_resolvers.py
      ğŸ“„ test_messages.py
      ğŸ“„ test_metrics.py
      ğŸ“„ test_models.py
      ğŸ“„ test_oot_registration.py
      ğŸ“„ test_openai_schema.py
      ğŸ“„ test_optional_middleware.py
      ğŸ“„ test_orca_metrics.py
      ğŸ“„ test_prompt_validation.py
      ğŸ“„ test_protocol.py
      ğŸ“„ test_response_api_mcp_tools.py
      ğŸ“„ test_response_api_with_harmony.py
      ğŸ“„ test_responses_function_call_parsing.py
      ğŸ“„ test_return_token_ids.py
      ğŸ“„ test_return_tokens_as_ids.py
      ğŸ“„ test_root_path.py
      ğŸ“„ test_run_batch.py
      ğŸ“„ test_serving_chat.py
      ğŸ“„ test_serving_engine.py
      ğŸ“„ test_serving_models.py
      ğŸ“„ test_serving_responses.py
      ğŸ“„ test_shutdown.py
      ğŸ“„ test_sleep.py
      ğŸ“„ test_tensorizer_entrypoint.py
      ğŸ“„ test_token_in_token_out.py
      ğŸ“„ test_tokenization.py
      ğŸ“„ test_transcription_validation.py
      ğŸ“„ test_translation_validation.py
      ğŸ“„ test_uds.py
      ğŸ“„ test_video.py
      ğŸ“„ test_vision.py
      ğŸ“„ test_vision_embeds.py
      ğŸ“ tool_parsers
      ğŸ“„ __init__.py
      ğŸ“ correctness
      ğŸ“ llm
      ğŸ“ openai
      ğŸ“„ __init__.py
      ğŸ“„ conftest.py
      ğŸ“„ test_gpqa_correctness.py
      ğŸ“„ README.md
      ğŸ“„ __init__.py
      ğŸ“ configs
      ğŸ“„ conftest.py
      ğŸ“„ gsm8k_eval.py
      ğŸ“„ test_gsm8k_correctness.py
      ğŸ“„ conftest.py
      ğŸ“„ test_aiter_flash_attn.py
      ğŸ“„ test_attention.py
      ğŸ“„ test_attention_selector.py
      ğŸ“„ test_cache.py
      ğŸ“„ test_cascade_flash_attn.py
      ğŸ“„ test_cutlass_mla_decode.py
      ğŸ“„ test_deepgemm_attention.py
      ğŸ“„ test_flash_attn.py
      ğŸ“„ test_flashinfer.py
      ğŸ“„ test_flashinfer_mla_decode.py
      ğŸ“„ test_flashinfer_trtllm_attention.py
      ğŸ“„ test_flashmla.py
      ğŸ“„ test_flashmla_sparse.py
      ğŸ“„ test_lightning_attn.py
      ğŸ“„ test_merge_attn_states.py
      ğŸ“„ test_mha_attn.py
      ğŸ“„ test_mla_decode_cpu.py
      ğŸ“„ test_pack_unpack_triton.py
      ğŸ“„ test_prefix_prefill.py
      ğŸ“„ test_rocm_attention_selector.py
      ğŸ“„ test_triton_decode_attention.py
      ğŸ“„ test_triton_unified_attention.py
      ğŸ“„ test_activation.py
      ğŸ“„ test_fused_quant_layernorm.py
      ğŸ“„ test_layernorm.py
      ğŸ“„ test_mrope.py
      ğŸ“„ test_opcheck.py
      ğŸ“„ test_permute_cols.py
      ğŸ“„ test_pos_encoding.py
      ğŸ“„ test_rotary_embedding.py
      ğŸ“„ test_uva.py
      ğŸ“„ test_causal_conv1d.py
      ğŸ“„ test_mamba_mixer2.py
      ğŸ“„ test_mamba_ssm.py
      ğŸ“„ test_mamba_ssm_ssd.py
      ğŸ“„ __init__.py
      ğŸ“ modular_kernel_tools
      ğŸ“„ parallel_utils.py
      ğŸ“„ test_batched_deepgemm.py
      ğŸ“„ test_batched_moe.py
      ğŸ“„ test_block_fp8.py
      ğŸ“„ test_block_int8.py
      ğŸ“„ test_count_expert_num_tokens.py
      ğŸ“„ test_cutlass_grouped_gemm.py
      ğŸ“„ test_cutlass_moe.py
      ğŸ“„ test_deepep_deepgemm_moe.py
      ğŸ“„ test_deepep_moe.py
      ğŸ“„ test_deepgemm.py
      ğŸ“„ test_flashinfer.py
      ğŸ“„ test_flashinfer_moe.py
      ğŸ“„ test_gpt_oss_triton_kernels.py
      ğŸ“„ test_grouped_topk.py
      ğŸ“„ test_modular_kernel_combinations.py
      ğŸ“„ test_moe.py
      ğŸ“„ test_moe_align_block_size.py
      ğŸ“„ test_moe_permute_unpermute.py
      ğŸ“„ test_nvfp4_moe.py
      ğŸ“„ test_ocp_mx_moe.py
      ğŸ“„ test_pplx_cutlass_moe.py
      ğŸ“„ test_pplx_moe.py
      ğŸ“„ test_rocm_aiter_topk.py
      ğŸ“„ test_silu_mul_fp8_quant_deep_gemm.py
      ğŸ“„ test_triton_moe_ptpc_fp8.py
      ğŸ“„ utils.py
      ğŸ“„ nvfp4_utils.py
      ğŸ“„ test_allspark_gemm.py
      ğŸ“„ test_awq.py
      ğŸ“„ test_awq_triton.py
      ğŸ“„ test_block_fp8.py
      ğŸ“„ test_block_int8.py
      ğŸ“„ test_cutlass_2of4_sparse.py
      ğŸ“„ test_cutlass_scaled_mm.py
      ğŸ“„ test_cutlass_w4a8.py
      ğŸ“„ test_flashinfer_nvfp4_scaled_mm.py
      ğŸ“„ test_flashinfer_scaled_mm.py
      ğŸ“„ test_fp8_quant.py
      ğŸ“„ test_fp8_quant_group.py
      ğŸ“„ test_ggml.py
      ğŸ“„ test_gguf.py
      ğŸ“„ test_gptq.py
      ğŸ“„ test_hadacore.py
      ğŸ“„ test_int8_kernel.py
      ğŸ“„ test_int8_quant.py
      ğŸ“„ test_machete_mm.py
      ğŸ“„ test_marlin_gemm.py
      ğŸ“„ test_mxfp4_qutlass.py
      ğŸ“„ test_nvfp4_quant.py
      ğŸ“„ test_nvfp4_qutlass.py
      ğŸ“„ test_nvfp4_scaled_mm.py
      ğŸ“„ test_per_token_group_quant.py
      ğŸ“„ test_rocm_skinny_gemms.py
      ğŸ“„ test_silu_mul_nvfp4_quant.py
      ğŸ“„ test_triton_scaled_mm.py
      ğŸ“„ __init__.py
      ğŸ“ fastsafetensors_loader
      ğŸ“ runai_model_streamer
      ğŸ“ tensorizer_loader
      ğŸ“„ test_registry.py
      ğŸ“„ test_sharded_state_loader.py
      ğŸ“„ mistral_small_3_chat.json
      ğŸ“„ pixtral_chat.json
      ğŸ“„ __init__.py
      ğŸ“ generation
      ğŸ“ generation_ppl_test
      ğŸ“ pooling
      ğŸ“ pooling_mteb_test
      ğŸ“„ __init__.py
      ğŸ“ generation
      ğŸ“ pooling
      ğŸ“ processing
      ğŸ“„ test_mapping.py
      ğŸ“„ __init__.py
      ğŸ“„ test_awq.py
      ğŸ“„ test_bitblas.py
      ğŸ“„ test_bitsandbytes.py
      ğŸ“„ test_fp8.py
      ğŸ“„ test_gguf.py
      ğŸ“„ test_gptq_bitblas.py
      ğŸ“„ test_gptq_marlin.py
      ğŸ“„ test_gptq_marlin_24.py
      ğŸ“„ test_modelopt.py
      ğŸ“„ test_mxfp4.py
      ğŸ“„ test_nvfp4.py
      ğŸ“„ image1.png
      ğŸ“„ image2.png
      ğŸ“„ rgba.png
      ğŸ“„ __init__.py
      ğŸ“„ test_filesystem_resolver.py
      ğŸ“ prithvi_io_processor
      ğŸ“„ setup.py
      ğŸ“„ setup.py
      ğŸ“ vllm_add_dummy_model
      ğŸ“„ setup.py
      ğŸ“ vllm_add_dummy_platform
      ğŸ“ dummy_stat_logger
      ğŸ“„ setup.py
      ğŸ“„ __init__.py
      ğŸ“„ conftest.py
      ğŸ“„ test_mistral_tool_calls.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ test_lora.py
      ğŸ“„ test_attention_backends.py
      ğŸ“„ test_attention_backends_selection.py
      ğŸ“„ test_attention_splitting.py
      ğŸ“„ test_batch_reordering.py
      ğŸ“„ test_chunked_local_attention.py
      ğŸ“„ test_mla_backends.py
      ğŸ“„ test_sparse_mla_backends.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ test_async_scheduler.py
      ğŸ“„ test_encoder_cache_manager.py
      ğŸ“„ test_kv_cache_utils.py
      ğŸ“„ test_kv_sharing.py
      ğŸ“„ test_prefix_caching.py
      ğŸ“„ test_scheduler.py
      ğŸ“„ test_scheduler_e2e.py
      ğŸ“„ test_single_type_kv_cache_manager.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ test_cudagraph_dispatch.py
      ğŸ“„ test_cudagraph_mode.py
      ğŸ“„ __init__.py
      ğŸ“„ test_async_llm_dp.py
      ğŸ“„ test_dbo.py
      ğŸ“„ test_external_lb_dp.py
      ğŸ“„ test_hybrid_lb_dp.py
      ğŸ“„ test_internal_lb_dp.py
      ğŸ“„ __init__.py
      ğŸ“„ test_async_scheduling.py
      ğŸ“„ test_cascade_attention.py
      ğŸ“„ test_correctness_sliding_window.py
      ğŸ“„ test_kv_sharing_fast_prefill.py
      ğŸ“„ test_min_tokens.py
      ğŸ“„ test_pooling_chunked_prefill.py
      ğŸ“„ test_spec_decode.py
      ğŸ“„ __init__.py
      ğŸ“„ conftest.py
      ğŸ“„ test_async_llm.py
      ğŸ“„ test_engine_args.py
      ğŸ“„ test_engine_core.py
      ğŸ“„ test_engine_core_client.py
      ğŸ“„ test_fast_incdec_prefix_err.py
      ğŸ“„ test_llm_engine.py
      ğŸ“„ test_output_processor.py
      ğŸ“„ test_processor_multi_modal_uuids.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ conftest.py
      ğŸ“ llm
      ğŸ“ openai
      ğŸ“„ __init__.py
      ğŸ“„ test_executor.py
      ğŸ“„ test_batch_invariance.py
      ğŸ“„ test_rms_norm_batch_invariant.py
      ğŸ“„ __init__.py
      ğŸ“ nixl_integration
      ğŸ“ unit
      ğŸ“„ test_cpu_gpu.py
      ğŸ“„ test_cpu_manager.py
      ğŸ“„ test_cpu_offloading.py
      ğŸ“„ test_worker.py
      ğŸ“„ __init__.py
      ğŸ“„ test_correctness.py
      ğŸ“„ test_custom_offline.py
      ğŸ“„ test_custom_online.py
      ğŸ“„ utils.py
      ğŸ“„ test_engine_logger_apis.py
      ğŸ“„ test_metrics_reader.py
      ğŸ“„ test_ray_metrics.py
      ğŸ“„ test_stats.py
      ğŸ“„ __init__.py
      ğŸ“„ test_logprobs.py
      ğŸ“„ test_logprobs_e2e.py
      ğŸ“„ test_rejection_sampler.py
      ğŸ“„ test_sampler.py
      ğŸ“„ test_sampling_params_e2e.py
      ğŸ“„ test_topk_topp_sampler.py
      ğŸ“„ utils.py
      ğŸ“„ test_delete.py
      ğŸ“„ test_forward_error.py
      ğŸ“„ test_processor_error.py
      ğŸ“„ test_startup_error.py
      ğŸ“„ utils.py
      ğŸ“„ test_eagle.py
      ğŸ“„ test_max_len.py
      ğŸ“„ test_mtp.py
      ğŸ“„ test_ngram.py
      ğŸ“„ test_speculators_eagle3.py
      ğŸ“„ test_tree_attention.py
      ğŸ“„ __init__.py
      ğŸ“„ test_gptoss_structural_tags.py
      ğŸ“„ test_reasoning_structured_output.py
      ğŸ“„ test_utils.py
      ğŸ“„ __init__.py
      ğŸ“„ test_basic.py
      ğŸ“„ test_kv_cache_update_kernel.py
      ğŸ“„ test_mha_attn.py
      ğŸ“„ test_multimodal.py
      ğŸ“„ test_pallas.py
      ğŸ“„ test_perf.py
      ğŸ“„ test_sampler.py
      ğŸ“„ test_spmd_model_weight_loading.py
      ğŸ“„ test_topk_topp_sampler.py
      ğŸ“„ test_tpu_int8.py
      ğŸ“„ test_tpu_qkv_linear.py
      ğŸ“ worker
      ğŸ“„ __init__.py
      ğŸ“„ test_tracing.py
      ğŸ“„ __init__.py
      ğŸ“„ test_gpu_input_batch.py
      ğŸ“„ test_gpu_model_runner.py
      ğŸ“„ test_utils.py
      ğŸ“„ test_worker_memory_snapshot.py
      ğŸ“„ __init__.py
      ğŸ“„ blame.py
      ğŸ“„ monitor.py
      ğŸ“„ eep_nvshmem.patch
      ğŸ“„ install_eep_libraries.sh
      ğŸ“„ README.md
      ğŸ“„ gputrc2graph.py
      ğŸ“ images
      ğŸ“„ vllm_engine_model.json
      ğŸ“„ __init__.py
      ğŸ“„ abstract.py
      ğŸ“„ registry.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ chunked_local_attention.py
      ğŸ“„ cross_attention.py
      ğŸ“„ encoder_only_attention.py
      ğŸ“„ __init__.py
      ğŸ“„ chunked_prefill_paged_decode.py
      ğŸ“„ common.py
      ğŸ“„ flashmla.py
      ğŸ“„ merge_attn_states.py
      ğŸ“„ paged_attn.py
      ğŸ“„ pallas_kv_cache_update.py
      ğŸ“„ prefix_prefill.py
      ğŸ“„ rocm_aiter_mla.py
      ğŸ“„ rocm_aiter_paged_attn.py
      ğŸ“„ triton_decode_attention.py
      ğŸ“„ triton_flash_attention.py
      ğŸ“„ triton_merge_attn_states.py
      ğŸ“„ triton_reshape_and_cache_flash.py
      ğŸ“„ triton_unified_attention.py
      ğŸ“„ vit_attn_wrappers.py
      ğŸ“„ __init__.py
      ğŸ“„ fa_utils.py
      ğŸ“„ kv_sharing_utils.py
      ğŸ“„ __init__.py
      ğŸ“„ endpoint_request_func.py
      ğŸ“„ ready_checker.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ cli.py
      ğŸ“„ param_sweep.py
      ğŸ“„ plot.py
      ğŸ“„ serve.py
      ğŸ“„ serve_sla.py
      ğŸ“„ server.py
      ğŸ“„ sla_sweep.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ all2all.py
      ğŸ“„ all_reduce_utils.py
      ğŸ“„ base_device_communicator.py
      ğŸ“„ cpu_communicator.py
      ğŸ“„ cuda_communicator.py
      ğŸ“„ cuda_wrapper.py
      ğŸ“„ custom_all_reduce.py
      ğŸ“„ mnnvl_compat.py
      ğŸ“„ pynccl.py
      ğŸ“„ pynccl_allocator.py
      ğŸ“„ pynccl_wrapper.py
      ğŸ“„ quick_all_reduce.py
      ğŸ“„ ray_communicator.py
      ğŸ“„ shm_broadcast.py
      ğŸ“„ shm_object_storage.py
      ğŸ“„ symm_mem.py
      ğŸ“„ tpu_communicator.py
      ğŸ“„ xpu_communicator.py
      ğŸ“„ __init__.py
      ğŸ“„ eplb_state.py
      ğŸ“„ rebalance_algo.py
      ğŸ“„ rebalance_execute.py
      ğŸ“„ README.md
      ğŸ“„ __init__.py
      ğŸ“„ disagg_prefill_workflow.jpg
      ğŸ“ kv_connector
      ğŸ“ kv_lookup_buffer
      ğŸ“ kv_pipe
      ğŸ“„ kv_transfer_state.py
      ğŸ“„ __init__.py
      ğŸ“„ protocol.py
      ğŸ“„ serving_messages.py
      ğŸ“„ __init__.py
      ğŸ“ benchmark
      ğŸ“„ collect_env.py
      ğŸ“„ main.py
      ğŸ“„ openai.py
      ğŸ“„ run_batch.py
      ğŸ“„ serve.py
      ğŸ“„ types.py
      ğŸ“„ __init__.py
      ğŸ“„ api_server.py
      ğŸ“„ cli_args.py
      ğŸ“„ orca_metrics.py
      ğŸ“„ protocol.py
      ğŸ“„ run_batch.py
      ğŸ“„ serving_chat.py
      ğŸ“„ serving_classification.py
      ğŸ“„ serving_completion.py
      ğŸ“„ serving_embedding.py
      ğŸ“„ serving_engine.py
      ğŸ“„ serving_models.py
      ğŸ“„ serving_pooling.py
      ğŸ“„ serving_responses.py
      ğŸ“„ serving_score.py
      ğŸ“„ serving_tokenization.py
      ğŸ“„ serving_transcription.py
      ğŸ“„ speech_to_text.py
      ğŸ“ tool_parsers
      ğŸ“„ __init__.py
      ğŸ“„ base.py
      ğŸ“„ base_linear.py
      ğŸ“„ column_parallel_linear.py
      ğŸ“„ fused_moe.py
      ğŸ“„ logits_processor.py
      ğŸ“„ replicated_linear.py
      ğŸ“„ row_parallel_linear.py
      ğŸ“„ utils.py
      ğŸ“„ vocal_parallel_embedding.py
      ğŸ“„ __init__.py
      ğŸ“ ipex_ops
      ğŸ“ torch_ops
      ğŸ“ triton_ops
      ğŸ“ xla_ops
      ğŸ“„ __init__.py
      ğŸ“„ punica_base.py
      ğŸ“„ punica_cpu.py
      ğŸ“„ punica_gpu.py
      ğŸ“„ punica_selector.py
      ğŸ“„ punica_tpu.py
      ğŸ“„ punica_xpu.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ activation.py
      ğŸ“„ attention_layer_base.py
      ğŸ“„ batch_invariant.py
      ğŸ“ fla
      ğŸ“ fused_moe
      ğŸ“„ kda.py
      ğŸ“„ layernorm.py
      ğŸ“„ lightning_attn.py
      ğŸ“„ linear.py
      ğŸ“„ logits_processor.py
      ğŸ“ mamba
      ğŸ“„ mla.py
      ğŸ“„ pooler.py
      ğŸ“ quantization
      ğŸ“„ resampler.py
      ğŸ“ rotary_embedding
      ğŸ“„ utils.py
      ğŸ“„ vocab_parallel_embedding.py
      ğŸ“„ __init__.py
      ğŸ“„ base_loader.py
      ğŸ“„ bitsandbytes_loader.py
      ğŸ“„ default_loader.py
      ğŸ“„ dummy_loader.py
      ğŸ“„ gguf_loader.py
      ğŸ“„ online_quantization.py
      ğŸ“„ runai_streamer_loader.py
      ğŸ“„ sharded_state_loader.py
      ğŸ“„ tensorizer.py
      ğŸ“„ tensorizer_loader.py
      ğŸ“„ tpu.py
      ğŸ“„ utils.py
      ğŸ“„ weight_utils.py
      ğŸ“„ __init__.py
      ğŸ“„ adapters.py
      ğŸ“„ aimv2.py
      ğŸ“„ apertus.py
      ğŸ“„ arcee.py
      ğŸ“„ arctic.py
      ğŸ“„ aria.py
      ğŸ“„ aya_vision.py
      ğŸ“„ baichuan.py
      ğŸ“„ bailing_moe.py
      ğŸ“„ bamba.py
      ğŸ“„ bee.py
      ğŸ“„ bert.py
      ğŸ“„ bert_with_rope.py
      ğŸ“„ blip.py
      ğŸ“„ blip2.py
      ğŸ“„ bloom.py
      ğŸ“„ chameleon.py
      ğŸ“„ chatglm.py
      ğŸ“„ clip.py
      ğŸ“„ cohere2_vision.py
      ğŸ“„ commandr.py
      ğŸ“„ config.py
      ğŸ“„ dbrx.py
      ğŸ“„ deepencoder.py
      ğŸ“„ deepseek.py
      ğŸ“„ deepseek_eagle.py
      ğŸ“„ deepseek_mtp.py
      ğŸ“„ deepseek_ocr.py
      ğŸ“„ deepseek_v2.py
      ğŸ“„ deepseek_vl2.py
      ğŸ“„ dots1.py
      ğŸ“„ dots_ocr.py
      ğŸ“„ ernie45.py
      ğŸ“„ ernie45_moe.py
      ğŸ“„ ernie45_vl.py
      ğŸ“„ ernie45_vl_moe.py
      ğŸ“„ ernie_mtp.py
      ğŸ“„ exaone.py
      ğŸ“„ exaone4.py
      ğŸ“„ fairseq2_llama.py
      ğŸ“„ falcon.py
      ğŸ“„ falcon_h1.py
      ğŸ“„ flex_olmo.py
      ğŸ“„ fuyu.py
      ğŸ“„ gemma.py
      ğŸ“„ gemma2.py
      ğŸ“„ gemma3.py
      ğŸ“„ gemma3_mm.py
      ğŸ“„ gemma3n.py
      ğŸ“„ gemma3n_mm.py
      ğŸ“„ glm.py
      ğŸ“„ glm4.py
      ğŸ“„ glm4_1v.py
      ğŸ“„ glm4_moe.py
      ğŸ“„ glm4_moe_mtp.py
      ğŸ“„ glm4v.py
      ğŸ“„ gpt2.py
      ğŸ“„ gpt_bigcode.py
      ğŸ“„ gpt_j.py
      ğŸ“„ gpt_neox.py
      ğŸ“„ gpt_oss.py
      ğŸ“„ granite.py
      ğŸ“„ granite_speech.py
      ğŸ“„ granitemoe.py
      ğŸ“„ granitemoehybrid.py
      ğŸ“„ granitemoeshared.py
      ğŸ“„ gritlm.py
      ğŸ“„ grok1.py
      ğŸ“„ h2ovl.py
      ğŸ“„ hunyuan_v1.py
      ğŸ“„ hyperclovax_vision.py
      ğŸ“„ idefics2_vision_model.py
      ğŸ“„ idefics3.py
      ğŸ“„ interfaces.py
      ğŸ“„ interfaces_base.py
      ğŸ“„ intern_vit.py
      ğŸ“„ internlm2.py
      ğŸ“„ internlm2_ve.py
      ğŸ“„ interns1.py
      ğŸ“„ interns1_vit.py
      ğŸ“„ internvl.py
      ğŸ“„ jais.py
      ğŸ“„ jamba.py
      ğŸ“„ jina_vl.py
      ğŸ“„ keye.py
      ğŸ“„ keye_vl1_5.py
      ğŸ“„ kimi_linear.py
      ğŸ“„ kimi_vl.py
      ğŸ“„ lfm2.py
      ğŸ“„ lfm2_moe.py
      ğŸ“„ lightonocr.py
      ğŸ“„ llama.py
      ğŸ“„ llama4.py
      ğŸ“„ llama4_eagle.py
      ğŸ“„ llama_eagle.py
      ğŸ“„ llama_eagle3.py
      ğŸ“„ llava.py
      ğŸ“„ llava_next.py
      ğŸ“„ llava_next_video.py
      ğŸ“„ llava_onevision.py
      ğŸ“„ longcat_flash.py
      ğŸ“„ longcat_flash_mtp.py
      ğŸ“„ mamba.py
      ğŸ“„ mamba2.py
      ğŸ“„ medusa.py
      ğŸ“„ midashenglm.py
      ğŸ“„ mimo.py
      ğŸ“„ mimo_mtp.py
      ğŸ“„ minicpm.py
      ğŸ“„ minicpm3.py
      ğŸ“„ minicpm_eagle.py
      ğŸ“„ minicpmo.py
      ğŸ“„ minicpmv.py
      ğŸ“„ minimax_m2.py
      ğŸ“„ minimax_text_01.py
      ğŸ“„ minimax_vl_01.py
      ğŸ“„ mistral3.py
      ğŸ“„ mixtral.py
      ğŸ“„ mllama4.py
      ğŸ“„ mlp_speculator.py
      ğŸ“„ modernbert.py
      ğŸ“„ module_mapping.py
      ğŸ“„ molmo.py
      ğŸ“„ moonvit.py
      ğŸ“„ mpt.py
      ğŸ“„ nano_nemotron_vl.py
      ğŸ“„ nemotron.py
      ğŸ“„ nemotron_h.py
      ğŸ“„ nemotron_nas.py
      ğŸ“„ nemotron_vl.py
      ğŸ“„ nvlm_d.py
      ğŸ“„ olmo.py
      ğŸ“„ olmo2.py
      ğŸ“„ olmoe.py
      ğŸ“„ openpangu.py
      ğŸ“„ openpangu_mtp.py
      ğŸ“„ opt.py
      ğŸ“„ orion.py
      ğŸ“„ ouro.py
      ğŸ“„ ovis.py
      ğŸ“„ ovis2_5.py
      ğŸ“„ paddleocr_vl.py
      ğŸ“„ paligemma.py
      ğŸ“„ persimmon.py
      ğŸ“„ phi.py
      ğŸ“„ phi3.py
      ğŸ“„ phi3v.py
      ğŸ“„ phi4_multimodal.py
      ğŸ“„ phi4mm.py
      ğŸ“„ phi4mm_audio.py
      ğŸ“„ phi4mm_utils.py
      ğŸ“„ phimoe.py
      ğŸ“„ pixtral.py
      ğŸ“„ plamo2.py
      ğŸ“„ qwen.py
      ğŸ“„ qwen2.py
      ğŸ“„ qwen2_5_omni_thinker.py
      ğŸ“„ qwen2_5_vl.py
      ğŸ“„ qwen2_audio.py
      ğŸ“„ qwen2_moe.py
      ğŸ“„ qwen2_rm.py
      ğŸ“„ qwen2_vl.py
      ğŸ“„ qwen3.py
      ğŸ“„ qwen3_moe.py
      ğŸ“„ qwen3_next.py
      ğŸ“„ qwen3_next_mtp.py
      ğŸ“„ qwen3_omni_moe_thinker.py
      ğŸ“„ qwen3_vl.py
      ğŸ“„ qwen3_vl_moe.py
      ğŸ“„ qwen_vl.py
      ğŸ“„ radio.py
      ğŸ“„ registry.py
      ğŸ“„ roberta.py
      ğŸ“„ rvl.py
      ğŸ“„ seed_oss.py
      ğŸ“„ siglip.py
      ğŸ“„ siglip2navit.py
      ğŸ“„ skyworkr1v.py
      ğŸ“„ smolvlm.py
      ğŸ“„ solar.py
      ğŸ“„ stablelm.py
      ğŸ“„ starcoder2.py
      ğŸ“„ step3_text.py
      ğŸ“„ step3_vl.py
      ğŸ“„ swin.py
      ğŸ“„ tarsier.py
      ğŸ“„ telechat2.py
      ğŸ“„ teleflm.py
      ğŸ“„ terratorch.py
      ğŸ“ transformers
      ğŸ“„ ultravox.py
      ğŸ“„ utils.py
      ğŸ“„ vision.py
      ğŸ“„ voxtral.py
      ğŸ“„ whisper.py
      ğŸ“„ zamba2.py
      ğŸ“„ __init__.py
      ğŸ“„ deep_gemm_warmup.py
      ğŸ“„ kernel_warmup.py
      ğŸ“„ __init__.py
      ğŸ“„ interface.py
      ğŸ“„ README.md
      ğŸ“„ __init__.py
      ğŸ“„ filesystem_resolver.py
      ğŸ“„ __init__.py
      ğŸ“„ registry.py
      ğŸ“„ template_basic.jinja
      ğŸ“„ template_blip2.jinja
      ğŸ“„ template_chatml.jinja
      ğŸ“„ template_deepseek_ocr.jinja
      ğŸ“„ template_deepseek_vl2.jinja
      ğŸ“„ template_fuyu.jinja
      ğŸ“„ template_minicpmv45.jinja
      ğŸ“„ __init__.py
      ğŸ“„ arctic.py
      ğŸ“„ chatglm.py
      ğŸ“„ deepseek_vl2.py
      ğŸ“„ dotsocr.py
      ğŸ“„ eagle.py
      ğŸ“„ falcon.py
      ğŸ“„ flex_olmo.py
      ğŸ“„ jais.py
      ğŸ“„ kimi_linear.py
      ğŸ“„ kimi_vl.py
      ğŸ“„ lfm2_moe.py
      ğŸ“„ medusa.py
      ğŸ“„ midashenglm.py
      ğŸ“„ mistral.py
      ğŸ“„ mlp_speculator.py
      ğŸ“„ moonvit.py
      ğŸ“„ nemotron.py
      ğŸ“„ nemotron_h.py
      ğŸ“„ olmo3.py
      ğŸ“„ ovis.py
      ğŸ“„ qwen3_next.py
      ğŸ“„ radio.py
      ğŸ“ speculators
      ğŸ“„ step3_vl.py
      ğŸ“„ ultravox.py
      ğŸ“„ __init__.py
      ğŸ“„ deepseek_ocr.py
      ğŸ“„ deepseek_vl2.py
      ğŸ“„ ovis.py
      ğŸ“„ ovis2_5.py
      ğŸ“„ __init__.py
      ğŸ“„ mistral.py
      ğŸ“„ __init__.py
      ğŸ“ backends
      ğŸ“„ __init__.py
      ğŸ“„ block_pool.py
      ğŸ“„ encoder_cache_manager.py
      ğŸ“„ kv_cache_coordinator.py
      ğŸ“„ kv_cache_manager.py
      ğŸ“„ kv_cache_utils.py
      ğŸ“ sched
      ğŸ“„ single_type_kv_cache_manager.py
      ğŸ“„ __init__.py
      ğŸ“„ async_llm.py
      ğŸ“„ coordinator.py
      ğŸ“„ core.py
      ğŸ“„ core_client.py
      ğŸ“„ detokenizer.py
      ğŸ“„ exceptions.py
      ğŸ“„ llm_engine.py
      ğŸ“„ logprobs.py
      ğŸ“„ output_processor.py
      ğŸ“„ parallel_sampling.py
      ğŸ“„ processor.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ abstract.py
      ğŸ“„ multiproc_executor.py
      ğŸ“„ ray_distributed_executor.py
      ğŸ“„ ray_executor.py
      ğŸ“„ ray_utils.py
      ğŸ“„ uniproc_executor.py
      ğŸ“„ __init__.py
      ğŸ“„ abstract.py
      ğŸ“„ backend.py
      ğŸ“ backends
      ğŸ“„ cpu.py
      ğŸ“„ factory.py
      ğŸ“„ lru_manager.py
      ğŸ“„ mediums.py
      ğŸ“„ spec.py
      ğŸ“ worker
      ğŸ“„ __init__.py
      ğŸ“„ loggers.py
      ğŸ“„ prometheus.py
      ğŸ“„ ray_wrappers.py
      ğŸ“„ reader.py
      ğŸ“„ stats.py
      ğŸ“„ __init__.py
      ğŸ“„ metadata.py
      ğŸ“„ __init__.py
      ğŸ“ logits_processor
      ğŸ“„ metadata.py
      ğŸ“ ops
      ğŸ“„ rejection_sampler.py
      ğŸ“„ sampler.py
      ğŸ“ tpu
      ğŸ“„ __init__.py
      ğŸ“„ eagle.py
      ğŸ“„ medusa.py
      ğŸ“„ metadata.py
      ğŸ“„ metrics.py
      ğŸ“„ ngram_proposer.py
      ğŸ“„ suffix_decoding.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ backend_guidance.py
      ğŸ“„ backend_lm_format_enforcer.py
      ğŸ“„ backend_outlines.py
      ğŸ“„ backend_types.py
      ğŸ“„ backend_xgrammar.py
      ğŸ“„ request.py
      ğŸ“„ utils.py
      ğŸ“„ __init__.py
      ğŸ“„ block_table.py
      ğŸ“„ cpu_model_runner.py
      ğŸ“„ cpu_worker.py
      ğŸ“„ dp_utils.py
      ğŸ“„ gpu_input_batch.py
      ğŸ“„ gpu_model_runner.py
      ğŸ“„ gpu_ubatch_wrapper.py
      ğŸ“„ gpu_worker.py
      ğŸ“„ kv_connector_model_runner_mixin.py
      ğŸ“„ lora_model_runner_mixin.py
      ğŸ“„ tpu_input_batch.py
      ğŸ“„ tpu_model_runner.py
      ğŸ“„ tpu_worker.py
      ğŸ“„ ubatch_utils.py
      ğŸ“„ ubatching.py
      ğŸ“„ utils.py
      ğŸ“„ worker_base.py
      ğŸ“„ xpu_model_runner.py
      ğŸ“„ xpu_worker.py
        ğŸ“ device
        ğŸ“ kernel
        ğŸ“„ hadamard_transform_cuda.cu
        ğŸ“„ LICENSE
        ğŸ“ common
        ğŸ“„ marlin_24_cuda_kernel.cu
        ğŸ“„ Epilogues.md
        ğŸ“ c3x
        ğŸ“ moe
        ğŸ“„ scaled_mm_c2x.cu
        ğŸ“„ scaled_mm_c2x.cuh
        ğŸ“„ scaled_mm_c2x_sm75_dispatch.cuh
        ğŸ“„ scaled_mm_c2x_sm80_dispatch.cuh
        ğŸ“„ scaled_mm_c2x_sm89_fp8_dispatch.cuh
        ğŸ“„ scaled_mm_c2x_sm89_int8_dispatch.cuh
        ğŸ“„ scaled_mm_c3x_sm100.cu
        ğŸ“„ scaled_mm_c3x_sm120.cu
        ğŸ“„ scaled_mm_c3x_sm90.cu
        ğŸ“„ scaled_mm_entry.cu
        ğŸ“ amd
        ğŸ“„ common.cu
        ğŸ“„ common.cuh
        ğŸ“ nvidia
        ğŸ“„ per_token_group_quant.cu
        ğŸ“„ per_token_group_quant.cu
        ğŸ“„ scaled_quant.cu
        ğŸ“„ entrypoints.excalidraw.png
        ğŸ“„ llm_engine.excalidraw.png
        ğŸ“„ current_design.png
        ğŸ“„ executor_runtime.png
        ğŸ“„ previous_design.png
        ğŸ“„ wrapper_flow.png
        ğŸ“„ design_diagram.png
        ğŸ“„ dynamic_shapes.png
        ğŸ“„ tlparse_inductor.png
        ğŸ“„ fused_experts_blocks.png
        ğŸ“„ fused_moe_batched.png
        ğŸ“„ fused_moe_non_batched.png
        ğŸ“„ prepare_and_finalize_blocks.png
        ğŸ“„ basic_grouping_example.png
        ğŸ“„ full_attn.png
        ğŸ“„ memory_layout.png
        ğŸ“„ overview.png
        ğŸ“„ sw_attn.png
        ğŸ“„ intervals-1.png
        ğŸ“„ intervals-2.png
        ğŸ“„ intervals-3.png
        ğŸ“„ k_vecs.png
        ğŸ“„ key.png
        ğŸ“„ logits_vec.png
        ğŸ“„ q_vecs.png
        ğŸ“„ query.png
        ğŸ“„ v_vec.png
        ğŸ“„ value.png
        ğŸ“„ example-time-1.png
        ğŸ“„ example-time-3.png
        ğŸ“„ example-time-4.png
        ğŸ“„ example-time-5.png
        ğŸ“„ example-time-6.png
        ğŸ“„ example-time-7.png
        ğŸ“„ free.png
        ğŸ“„ overview.png
        ğŸ“„ most_model_len.png
        ğŸ“„ abstraction.jpg
        ğŸ“„ high_level_design.png
        ğŸ“„ overview.jpg
        ğŸ“„ workflow.png
        ğŸ“„ plot.md
        ğŸ“„ serve.md
        ğŸ“„ serve_sla.md
        ğŸ“„ toc-item.html
        ğŸ“„ _helpers.tpl
        ğŸ“„ configmap.yaml
        ğŸ“„ custom-objects.yaml
        ğŸ“„ deployment.yaml
        ğŸ“„ hpa.yaml
        ğŸ“„ job.yaml
        ğŸ“„ poddisruptionbudget.yaml
        ğŸ“„ pvc.yaml
        ğŸ“„ secrets.yaml
        ğŸ“„ service.yaml
        ğŸ“„ README.md
        ğŸ“„ performance_statistics.json
        ğŸ“„ query_statistics.json
        ğŸ“„ README.md
        ğŸ“„ performance_statistics.yaml
        ğŸ“„ query_statistics.yaml
        ğŸ“ configs
        ğŸ“„ disagg_example_nixl.sh
        ğŸ“„ disagg_proxy_server.py
        ğŸ“„ disagg_vllm_launcher.sh
        ğŸ“„ __init__.py
        ğŸ“„ test_lmeval.py
        ğŸ“„ test_transcription_api_correctness.py
        ğŸ“„ __init__.py
        ğŸ“„ conftest.py
        ğŸ“„ test_hermes_tool_parser.py
        ğŸ“„ test_hunyuan_a13b_tool_parser.py
        ğŸ“„ test_llama3_json_tool_parser.py
        ğŸ“„ test_llama4_pythonic_tool_parser.py
        ğŸ“„ test_olmo3_tool_parser.py
        ğŸ“„ test_pythonic_tool_parser.py
        ğŸ“„ utils.py
        ğŸ“„ __init__.py
        ğŸ“„ test_mteb_embed.py
        ğŸ“„ test_mteb_score.py
        ğŸ“„ __init__.py
        ğŸ“„ test_classify.py
        ğŸ“„ test_embedding.py
        ğŸ“„ test_encode.py
        ğŸ“„ test_reward.py
        ğŸ“„ test_score.py
        ğŸ“„ __init__.py
        ğŸ“„ test_classification.py
        ğŸ“„ test_embedding.py
        ğŸ“„ test_embedding_dimensions.py
        ğŸ“„ test_embedding_long_text.py
        ğŸ“„ test_pooling.py
        ğŸ“„ test_rerank.py
        ğŸ“„ test_score.py
        ğŸ“„ test_truncation.py
        ğŸ“„ test_vision_embedding.py
        ğŸ“„ DeepSeek-V2-Lite-Instruct-FP8.yaml
        ğŸ“„ Llama-3-8B-Instruct-nonuniform-CT.yaml
        ğŸ“„ Llama-3.2-1B-Instruct-INT8-CT.yaml
        ğŸ“„ Qwen1.5-MoE-W4A16-CT.yaml
        ğŸ“„ Qwen2.5-VL-3B-Instruct-FP8-dynamic.yaml
        ğŸ“„ Qwen3-0.6B-FP8.yaml
        ğŸ“„ Qwen3-30B-A3B-NVFP4.yaml
        ğŸ“„ models-blackwell.txt
        ğŸ“„ models-small.txt
        ğŸ“„ __init__.py
        ğŸ“„ cli_args.py
        ğŸ“„ common.py
        ğŸ“„ make_feature_matrix.py
        ğŸ“„ mk_objects.py
        ğŸ“„ parallel_utils.py
        ğŸ“„ profile_modular_kernel.py
        ğŸ“„ __init__.py
        ğŸ“„ test_fastsafetensors_loader.py
        ğŸ“„ test_weight_utils.py
        ğŸ“„ __init__.py
        ğŸ“„ test_runai_model_streamer_loader.py
        ğŸ“„ test_runai_utils.py
        ğŸ“„ test_weight_utils.py
        ğŸ“„ __init__.py
        ğŸ“„ conftest.py
        ğŸ“„ test_tensorizer.py
        ğŸ“„ __init__.py
        ğŸ“„ test_common.py
        ğŸ“„ test_gemma.py
        ğŸ“„ test_granite.py
        ğŸ“„ test_hybrid.py
        ğŸ“„ test_mistral.py
        ğŸ“„ test_phimoe.py
        ğŸ“„ __init__.py
        ğŸ“„ ppl_utils.py
        ğŸ“„ test_gemma.py
        ğŸ“„ test_gpt.py
        ğŸ“„ test_qwen.py
        ğŸ“„ __init__.py
        ğŸ“„ embed_utils.py
        ğŸ“„ test_auto_prefix_cache_support.py
        ğŸ“„ test_classification.py
        ğŸ“„ test_embedding.py
        ğŸ“„ test_extract_hidden_states.py
        ğŸ“„ test_gritlm.py
        ğŸ“„ test_head_dtype.py
        ğŸ“„ test_mm_classifier_conversion.py
        ğŸ“„ test_multi_vector_retrieval.py
        ğŸ“„ test_multilabel_classification_support.py
        ğŸ“„ test_nomic_max_model_len.py
        ğŸ“„ test_pooler_config_init_behaviour.py
        ğŸ“„ test_reward.py
        ğŸ“„ test_scoring.py
        ğŸ“„ test_splade_sparse_pooler.py
        ğŸ“„ test_token_classification.py
        ğŸ“„ test_truncation_control.py
        ğŸ“„ __init__.py
        ğŸ“„ mteb_utils.py
        ğŸ“„ test_baai.py
        ğŸ“„ test_bge_reranker_v2_gemma.py
        ğŸ“„ test_cross_encoder.py
        ğŸ“„ test_gte.py
        ğŸ“„ test_intfloat.py
        ğŸ“„ test_jina.py
        ğŸ“„ test_mxbai_rerank.py
        ğŸ“„ test_nomic.py
        ğŸ“„ test_qwen3_reranker.py
        ğŸ“„ test_snowflake_arctic_embed.py
        ğŸ“„ test_st_projector.py
        ğŸ“„ __init__.py
        ğŸ“„ test_common.py
        ğŸ“„ test_granite_speech.py
        ğŸ“„ test_interleaved.py
        ğŸ“„ test_keye.py
        ğŸ“„ test_maverick.py
        ğŸ“„ test_phi4_multimodal.py
        ğŸ“„ test_phi4mm.py
        ğŸ“„ test_pixtral.py
        ğŸ“„ test_qwen2_5_vl.py
        ğŸ“„ test_qwen2_vl.py
        ğŸ“„ test_ultravox.py
        ğŸ“„ test_voxtral.py
        ğŸ“„ test_whisper.py
        ğŸ“ vlm_utils
        ğŸ“„ __init__.py
        ğŸ“„ test_clip.py
        ğŸ“„ test_dse_qwen2_vl.py
        ğŸ“„ test_intern_vit.py
        ğŸ“„ test_jinavl_reranker.py
        ğŸ“„ test_llava_next.py
        ğŸ“„ test_phi3v.py
        ğŸ“„ test_prithvi_mae.py
        ğŸ“„ test_radio.py
        ğŸ“„ test_siglip.py
        ğŸ“„ __init__.py
        ğŸ“„ test_common.py
        ğŸ“„ test_glm4_1v.py
        ğŸ“„ test_h2ovl.py
        ğŸ“„ test_idefics3.py
        ğŸ“„ test_internvl.py
        ğŸ“„ test_llama4.py
        ğŸ“„ test_llava_next.py
        ğŸ“„ test_llava_onevision.py
        ğŸ“„ test_minimax_vl_01.py
        ğŸ“„ test_mllama4.py
        ğŸ“„ test_nemotron_vl.py
        ğŸ“„ test_phi3v.py
        ğŸ“„ test_phi4mm.py
        ğŸ“„ test_qwen2_vl.py
        ğŸ“„ test_smolvlm.py
        ğŸ“„ test_tensor_schema.py
        ğŸ“„ test_transformers.py
        ğŸ“„ __init__.py
        ğŸ“„ prithvi_processor.py
        ğŸ“„ types.py
        ğŸ“„ __init__.py
        ğŸ“„ my_gemma_embedding.py
        ğŸ“„ my_llava.py
        ğŸ“„ my_opt.py
        ğŸ“„ __init__.py
        ğŸ“„ dummy_attention_backend.py
        ğŸ“„ dummy_custom_ops.py
        ğŸ“„ dummy_platform.py
        ğŸ“„ dummy_stat_logger.py
        ğŸ“„ __init__.py
        ğŸ“„ test_struct_output_generate.py
        ğŸ“ serving_responses
        ğŸ“„ test_chat_completion.py
        ğŸ“„ test_completion.py
        ğŸ“„ test_completion_with_image_embeds.py
        ğŸ“„ test_multi_api_servers.py
        ğŸ“„ run_accuracy_test.sh
        ğŸ“„ run_edge_case_test.sh
        ğŸ“„ run_tpu_disagg_accuracy_test.sh
        ğŸ“„ run_tpu_edge_case_test.sh
        ğŸ“„ test_accuracy.py
        ğŸ“„ test_disagg_accuracy.py
        ğŸ“„ test_edge_cases.py
        ğŸ“„ toy_proxy_server.py
        ğŸ“„ tp_config_sweep_accuracy_test.sh
        ğŸ“„ __init__.py
        ğŸ“„ test_backwards_compatibility.py
        ğŸ“„ test_config.py
        ğŸ“„ test_decode_bench_connector.py
        ğŸ“„ test_kv_connector_lifecyle.py
        ğŸ“„ test_kv_load_failure_recovery.py
        ğŸ“„ test_lmcache_integration.py
        ğŸ“„ test_multi_connector.py
        ğŸ“„ test_nixl_connector.py
        ğŸ“„ test_offloading_connector.py
        ğŸ“„ test_output_aggregator.py
        ğŸ“„ test_remote_decode_lifecycle.py
        ğŸ“„ test_remote_prefill_lifecycle.py
        ğŸ“„ test_shared_storage_connector.py
        ğŸ“„ utils.py
        ğŸ“„ __init__.py
        ğŸ“„ test_tpu_model_runner.py
        ğŸ“„ csv1.png
        ğŸ“„ html.png
        ğŸ“„ html_tbl.png
        ğŸ“„ __init__.py
        ğŸ“„ base.py
        ğŸ“„ factory.py
        ğŸ“„ utils.py
        ğŸ“ v1
        ğŸ“„ __init__.py
        ğŸ“„ base.py
        ğŸ“„ mooncake_store.py
        ğŸ“„ simple_buffer.py
        ğŸ“„ __init__.py
        ğŸ“„ base.py
        ğŸ“„ mooncake_pipe.py
        ğŸ“„ pynccl_pipe.py
        ğŸ“„ __init__.py
        ğŸ“„ base.py
        ğŸ“„ latency.py
        ğŸ“„ main.py
        ğŸ“„ serve.py
        ğŸ“„ sweep.py
        ğŸ“„ throughput.py
        ğŸ“„ __init__.py
        ğŸ“„ abstract_tool_parser.py
        ğŸ“„ deepseekv31_tool_parser.py
        ğŸ“„ deepseekv3_tool_parser.py
        ğŸ“„ ernie45_tool_parser.py
        ğŸ“„ glm4_moe_tool_parser.py
        ğŸ“„ granite_20b_fc_tool_parser.py
        ğŸ“„ granite_tool_parser.py
        ğŸ“„ hermes_tool_parser.py
        ğŸ“„ hunyuan_a13b_tool_parser.py
        ğŸ“„ internlm2_tool_parser.py
        ğŸ“„ jamba_tool_parser.py
        ğŸ“„ kimi_k2_tool_parser.py
        ğŸ“„ llama4_pythonic_tool_parser.py
        ğŸ“„ llama_tool_parser.py
        ğŸ“„ longcat_tool_parser.py
        ğŸ“„ minimax_m2_tool_parser.py
        ğŸ“„ minimax_tool_parser.py
        ğŸ“„ mistral_tool_parser.py
        ğŸ“„ olmo3_tool_parser.py
        ğŸ“„ openai_tool_parser.py
        ğŸ“„ phi4mini_tool_parser.py
        ğŸ“„ pythonic_tool_parser.py
        ğŸ“„ qwen3coder_tool_parser.py
        ğŸ“„ qwen3xml_tool_parser.py
        ğŸ“„ seed_oss_tool_parser.py
        ğŸ“„ step3_tool_parser.py
        ğŸ“„ utils.py
        ğŸ“„ xlam_tool_parser.py
        ğŸ“„ __init__.py
        ğŸ“„ lora_ops.py
        ğŸ“„ __init__.py
        ğŸ“„ lora_ops.py
        ğŸ“„ README_TUNING.md
        ğŸ“„ __init__.py
        ğŸ“„ fused_moe_lora_op.py
        ğŸ“„ kernel_utils.py
        ğŸ“„ lora_expand_op.py
        ğŸ“„ lora_kernel_metadata.py
        ğŸ“„ lora_shrink_op.py
        ğŸ“„ utils.py
        ğŸ“„ __init__.py
        ğŸ“„ lora_ops.py
        ğŸ“„ __init__.py
        ğŸ“ ops
        ğŸ“„ __init__.py
        ğŸ“„ batched_deep_gemm_moe.py
        ğŸ“„ batched_triton_or_deep_gemm_moe.py
        ğŸ“„ config.py
        ğŸ“ configs
        ğŸ“„ cpu_fused_moe.py
        ğŸ“„ cutlass_moe.py
        ğŸ“„ deep_gemm_moe.py
        ğŸ“„ deep_gemm_utils.py
        ğŸ“„ deepep_ht_prepare_finalize.py
        ğŸ“„ deepep_ll_prepare_finalize.py
        ğŸ“„ flashinfer_cutlass_moe.py
        ğŸ“„ flashinfer_cutlass_prepare_finalize.py
        ğŸ“„ flashinfer_trtllm_moe.py
        ğŸ“„ fused_batched_moe.py
        ğŸ“„ fused_marlin_moe.py
        ğŸ“„ fused_moe.py
        ğŸ“„ gpt_oss_triton_kernels_moe.py
        ğŸ“„ layer.py
        ğŸ“„ modular_kernel.py
        ğŸ“„ moe_align_block_size.py
        ğŸ“„ moe_pallas.py
        ğŸ“„ moe_permute_unpermute.py
        ğŸ“„ moe_torch_iterative.py
        ğŸ“„ pplx_prepare_finalize.py
        ğŸ“„ prepare_finalize.py
        ğŸ“„ rocm_aiter_fused_moe.py
        ğŸ“„ routing_simulator.py
        ğŸ“„ shared_fused_moe.py
        ğŸ“„ topk_weight_and_reduce.py
        ğŸ“„ triton_deep_gemm_moe.py
        ğŸ“„ trtllm_moe.py
        ğŸ“„ utils.py
        ğŸ“„ __init__.py
        ğŸ“„ abstract.py
        ğŸ“„ linear_attn.py
        ğŸ“„ mamba_mixer.py
        ğŸ“„ mamba_mixer2.py
        ğŸ“„ mamba_utils.py
        ğŸ“ ops
        ğŸ“„ short_conv.py
        ğŸ“„ __init__.py
        ğŸ“„ auto_round.py
        ğŸ“„ awq.py
        ğŸ“„ awq_marlin.py
        ğŸ“„ awq_triton.py
        ğŸ“„ base_config.py
        ğŸ“„ bitblas.py
        ğŸ“„ bitsandbytes.py
        ğŸ“ compressed_tensors
        ğŸ“„ deepspeedfp.py
        ğŸ“„ experts_int8.py
        ğŸ“„ fbgemm_fp8.py
        ğŸ“„ fp8.py
        ğŸ“„ fp_quant.py
        ğŸ“„ gguf.py
        ğŸ“„ gptq.py
        ğŸ“„ gptq_bitblas.py
        ğŸ“„ gptq_marlin.py
        ğŸ“„ gptq_marlin_24.py
        ğŸ“„ hqq_marlin.py
        ğŸ“„ inc.py
        ğŸ“„ input_quant_fp8.py
        ğŸ“„ ipex_quant.py
        ğŸ“ kernels
        ğŸ“„ kv_cache.py
        ğŸ“„ modelopt.py
        ğŸ“„ moe_wna16.py
        ğŸ“„ mxfp4.py
        ğŸ“„ petit.py
        ğŸ“„ ptpc_fp8.py
        ğŸ“ quark
        ğŸ“„ qutlass_utils.py
        ğŸ“„ rtn.py
        ğŸ“„ schema.py
        ğŸ“„ torchao.py
        ğŸ“„ tpu_int8.py
        ğŸ“ utils
        ğŸ“„ __init__.py
        ğŸ“„ base.py
        ğŸ“„ common.py
        ğŸ“„ deepseek_scaling_rope.py
        ğŸ“„ dual_chunk_rope.py
        ğŸ“„ dynamic_ntk_alpha_rope.py
        ğŸ“„ dynamic_ntk_scaling_rope.py
        ğŸ“„ ernie45_vl_rope.py
        ğŸ“„ linear_scaling_rope.py
        ğŸ“„ llama3_rope.py
        ğŸ“„ llama4_vision_rope.py
        ğŸ“„ mrope.py
        ğŸ“„ ntk_scaling_rope.py
        ğŸ“„ phi3_long_rope_scaled_rope.py
        ğŸ“„ rocm_aiter_rope_ops.py
        ğŸ“„ yarn_scaling_rope.py
        ğŸ“„ __init__.py
        ğŸ“„ base.py
        ğŸ“„ causal.py
        ğŸ“„ legacy.py
        ğŸ“„ moe.py
        ğŸ“„ multimodal.py
        ğŸ“„ pooling.py
        ğŸ“„ utils.py
        ğŸ“„ __init__.py
        ğŸ“„ algos.py
        ğŸ“„ base.py
        ğŸ“„ __init__.py
        ğŸ“„ cpu_attn.py
        ğŸ“„ flash_attn.py
        ğŸ“„ flashinfer.py
        ğŸ“„ flex_attention.py
        ğŸ“„ gdn_attn.py
        ğŸ“„ linear_attn.py
        ğŸ“„ mamba1_attn.py
        ğŸ“„ mamba2_attn.py
        ğŸ“„ mamba_attn.py
        ğŸ“ mla
        ğŸ“„ pallas.py
        ğŸ“„ rocm_aiter_fa.py
        ğŸ“„ rocm_aiter_unified_attn.py
        ğŸ“„ rocm_attn.py
        ğŸ“„ short_conv_attn.py
        ğŸ“„ tree_attn.py
        ğŸ“„ triton_attn.py
        ğŸ“„ utils.py
        ğŸ“„ xformers.py
        ğŸ“„ __init__.py
        ğŸ“„ async_scheduler.py
        ğŸ“„ interface.py
        ğŸ“„ output.py
        ğŸ“„ request_queue.py
        ğŸ“„ scheduler.py
        ğŸ“„ utils.py
        ğŸ“„ __init__.py
        ğŸ“„ cpu.py
        ğŸ“„ __init__.py
        ğŸ“„ cpu_gpu.py
        ğŸ“„ worker.py
        ğŸ“„ __init__.py
        ğŸ“„ builtin.py
        ğŸ“„ interface.py
        ğŸ“„ state.py
        ğŸ“„ __init__.py
        ğŸ“„ bad_words.py
        ğŸ“„ logprobs.py
        ğŸ“„ penalties.py
        ğŸ“„ topk_topp_sampler.py
        ğŸ“„ __init__.py
        ğŸ“„ metadata.py
        ğŸ“„ sampler.py
          ğŸ“„ sm100_mla.hpp
          ğŸ“„ sm100_fmha_mla_reduction.hpp
          ğŸ“„ sm100_fmha_mla_tma_warpspecialized.hpp
          ğŸ“„ sm100_mla_tile_scheduler.hpp
          ğŸ“„ base.h
          ğŸ“„ mem.h
          ğŸ“„ mma.h
          ğŸ“„ cutlass_gemm_caller.cuh
          ğŸ“„ scaled_mm.cuh
          ğŸ“„ scaled_mm_azp_sm90_int8.cu
          ğŸ“„ scaled_mm_blockwise_sm100_fp8.cu
          ğŸ“„ scaled_mm_blockwise_sm100_fp8_dispatch.cuh
          ğŸ“„ scaled_mm_blockwise_sm120_fp8.cu
          ğŸ“„ scaled_mm_blockwise_sm120_fp8_dispatch.cuh
          ğŸ“„ scaled_mm_blockwise_sm90_fp8.cu
          ğŸ“„ scaled_mm_blockwise_sm90_fp8_dispatch.cuh
          ğŸ“„ scaled_mm_helper.hpp
          ğŸ“„ scaled_mm_kernels.hpp
          ğŸ“„ scaled_mm_sm100_fp8.cu
          ğŸ“„ scaled_mm_sm100_fp8_dispatch.cuh
          ğŸ“„ scaled_mm_sm120_fp8.cu
          ğŸ“„ scaled_mm_sm120_fp8_dispatch.cuh
          ğŸ“„ scaled_mm_sm90_fp8.cu
          ğŸ“„ scaled_mm_sm90_fp8_dispatch.cuh
          ğŸ“„ scaled_mm_sm90_int8.cu
          ğŸ“„ scaled_mm_sm90_int8_dispatch.cuh
          ğŸ“„ blockwise_scaled_group_mm_sm100.cu
          ğŸ“„ get_group_starts.cuh
          ğŸ“„ grouped_mm_c3x.cuh
          ğŸ“„ grouped_mm_c3x_sm100.cu
          ğŸ“„ grouped_mm_c3x_sm90.cu
          ğŸ“„ moe_data.cu
          ğŸ“„ quant_utils.cuh
          ğŸ“„ quant_utils.cuh
          ğŸ“„ lmcache-decoder-config.yaml
          ğŸ“„ lmcache-prefiller-config.yaml
          ğŸ“„ __init__.py
          ğŸ“„ builders.py
          ğŸ“„ case_filtering.py
          ğŸ“„ core.py
          ğŸ“„ custom_inputs.py
          ğŸ“„ model_utils.py
          ğŸ“„ runners.py
          ğŸ“„ types.py
          ğŸ“„ __init__.py
          ğŸ“„ conftest.py
          ğŸ“„ test_basic.py
          ğŸ“„ test_function_call.py
          ğŸ“„ test_image.py
          ğŸ“„ test_stateful.py
          ğŸ“„ test_structured_output.py
          ğŸ“„ __init__.py
          ğŸ“„ base.py
          ğŸ“„ decode_bench_connector.py
          ğŸ“„ lmcache_connector.py
          ğŸ“ lmcache_integration
          ğŸ“„ metrics.py
          ğŸ“„ multi_connector.py
          ğŸ“„ nixl_connector.py
          ğŸ“„ offloading_connector.py
          ğŸ“ p2p
          ğŸ“„ shared_storage_connector.py
          ğŸ“„ __init__.py
          ğŸ“„ chunk.py
          ğŸ“„ chunk_delta_h.py
          ğŸ“„ chunk_o.py
          ğŸ“„ chunk_scaled_dot_kkt.py
          ğŸ“„ cumsum.py
          ğŸ“„ fused_recurrent.py
          ğŸ“„ index.py
          ğŸ“„ kda.py
          ğŸ“„ l2norm.py
          ğŸ“„ layernorm_guard.py
          ğŸ“„ op.py
          ğŸ“„ solve_tril.py
          ğŸ“„ utils.py
          ğŸ“„ wy_fast.py
          ğŸ“„ E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
          ğŸ“„ E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
          ğŸ“„ E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=1,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json
          ğŸ“„ E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
          ğŸ“„ E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json
          ğŸ“„ E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=1,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json
          ğŸ“„ E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
          ğŸ“„ E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=1,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json
          ğŸ“„ E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
          ğŸ“„ E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=1,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json
          ğŸ“„ E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json
          ğŸ“„ E=128,N=1024,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=128,N=1024,device_name=NVIDIA_H100,dtype=fp8_w8a8.json
          ğŸ“„ E=128,N=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=128,N=1024,device_name=NVIDIA_H200.json
          ğŸ“„ E=128,N=1856,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=128,N=1856,device_name=NVIDIA_L40S.json
          ğŸ“„ E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=128,N=192,device_name=NVIDIA_H20-3e.json
          ğŸ“„ E=128,N=192,device_name=NVIDIA_H20.json
          ğŸ“„ E=128,N=192,device_name=NVIDIA_H200.json
          ğŸ“„ E=128,N=352,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=384,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=384,device_name=NVIDIA_H20-3e.json
          ğŸ“„ E=128,N=384,device_name=NVIDIA_H20.json
          ğŸ“„ E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=384,device_name=NVIDIA_H200.json
          ğŸ“„ E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=128,N=704,device_name=NVIDIA_B200,dtype=fp8_w8a8.json
          ğŸ“„ E=128,N=704,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=768,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=768,device_name=NVIDIA_H20.json
          ğŸ“„ E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=128,N=768,device_name=NVIDIA_H200.json
          ğŸ“„ E=128,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=bf16.json
          ğŸ“„ E=128,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=128,N=928,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=128,N=928,device_name=NVIDIA_L40S.json
          ğŸ“„ E=128,N=96,device_name=NVIDIA_H20.json
          ğŸ“„ E=16,N=1024,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json
          ğŸ“„ E=16,N=1024,device_name=NVIDIA_B200.json
          ğŸ“„ E=16,N=1024,device_name=NVIDIA_H100.json
          ğŸ“„ E=16,N=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=16,N=1024,device_name=NVIDIA_H200.json
          ğŸ“„ E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json
          ğŸ“„ E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=16,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=16,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=16,N=2048,device_name=NVIDIA_H200.json
          ğŸ“„ E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json
          ğŸ“„ E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=16,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json
          ğŸ“„ E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json
          ğŸ“„ E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=160,N=192,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=160,N=192,device_name=AMD_Instinct_MI350_OAM,dtype=fp8_w8a8.json
          ğŸ“„ E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json
          ğŸ“„ E=160,N=192,device_name=NVIDIA_H20-3e.json
          ğŸ“„ E=160,N=320,device_name=NVIDIA_H20-3e.json
          ğŸ“„ E=160,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json
          ğŸ“„ E=160,N=384,device_name=AMD_Instinct_MI350_OAM,dtype=fp8_w8a8.json
          ğŸ“„ E=160,N=384,device_name=AMD_Instinct_MI355_OAM,dtype=fp8_w8a8.json
          ğŸ“„ E=160,N=640,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=160,N=640,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=160,N=640,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=20,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=20,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=20,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json
          ğŸ“„ E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json
          ğŸ“„ E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json
          ğŸ“„ E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=256,N=512,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json
          ğŸ“„ E=32,N=1408,device_name=NVIDIA_B200.json
          ğŸ“„ E=32,N=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=32,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=384,N=128,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=384,N=128,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=384,N=128,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=384,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=384,N=256,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=40,N=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8.json
          ğŸ“„ E=40,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=40,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=40,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=512,N=128,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=512,N=128,device_name=NVIDIA_B200.json
          ğŸ“„ E=512,N=128,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json
          ğŸ“„ E=512,N=128,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=512,N=128,device_name=NVIDIA_H20-3e.json
          ğŸ“„ E=512,N=128,device_name=NVIDIA_H200.json
          ğŸ“„ E=512,N=256,device_name=NVIDIA_B200.json
          ğŸ“„ E=512,N=256,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json
          ğŸ“„ E=512,N=256,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=512,N=256,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=512,N=256,device_name=NVIDIA_H20-3e.json
          ğŸ“„ E=512,N=256,device_name=NVIDIA_H200.json
          ğŸ“„ E=512,N=512,device_name=NVIDIA_B200.json
          ğŸ“„ E=512,N=512,device_name=NVIDIA_GB200,dtype=fp8_w8a8.json
          ğŸ“„ E=512,N=512,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=512,N=512,device_name=NVIDIA_H20-3e.json
          ğŸ“„ E=512,N=512,device_name=NVIDIA_H200.json
          ğŸ“„ E=512,N=64,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=512,N=64,device_name=NVIDIA_B200.json
          ğŸ“„ E=512,N=64,device_name=NVIDIA_H20-3e.json
          ğŸ“„ E=512,N=64,device_name=NVIDIA_H200.json
          ğŸ“„ E=60,N=1408,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=60,N=176,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=60,N=352,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=60,N=704,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=62,N=128,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=62,N=256,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=62,N=512,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json
          ğŸ“„ E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=1280,device_name=NVIDIA_H200.json
          ğŸ“„ E=64,N=1408,device_name=NVIDIA_B200.json
          ğŸ“„ E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=2560,device_name=NVIDIA_H200.json
          ğŸ“„ E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=3072,device_name=NVIDIA_H20.json
          ğŸ“„ E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=320,device_name=NVIDIA_H200.json
          ğŸ“„ E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=384,device_name=NVIDIA_H20.json
          ğŸ“„ E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json
          ğŸ“„ E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=640,device_name=NVIDIA_H200.json
          ğŸ“„ E=64,N=768,device_name=NVIDIA_H100_PCIe,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json
          ğŸ“„ E=64,N=768,device_name=NVIDIA_H20.json
          ğŸ“„ E=64,N=896,device_name=NVIDIA_H20.json
          ğŸ“„ E=64,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=bf16.json
          ğŸ“„ E=64,N=8960,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=72,N=192,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=72,N=384,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=72,N=768,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=14336,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=14336,device_name=AMD_Instinct_MI325X.json
          ğŸ“„ E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=14336,device_name=NVIDIA_H200.json
          ğŸ“„ E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=16384,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=16384,device_name=AMD_Instinct_MI325X.json
          ğŸ“„ E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=1792,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=1792,device_name=AMD_Instinct_MI325X.json
          ğŸ“„ E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json
          ğŸ“„ E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=1792,device_name=NVIDIA_H200.json
          ğŸ“„ E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=2048,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=2048,device_name=AMD_Instinct_MI325X.json
          ğŸ“„ E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
          ğŸ“„ E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=2048,device_name=NVIDIA_H200.json
          ğŸ“„ E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=3584,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=3584,device_name=AMD_Instinct_MI325X.json
          ğŸ“„ E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json
          ğŸ“„ E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=3584,device_name=NVIDIA_H200.json
          ğŸ“„ E=8,N=3584,device_name=NVIDIA_L40S.json
          ğŸ“„ E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=4096,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=4096,device_name=AMD_Instinct_MI325X.json
          ğŸ“„ E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=4096,device_name=NVIDIA_H200.json
          ğŸ“„ E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=7168,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=7168,device_name=AMD_Instinct_MI325X.json
          ğŸ“„ E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json
          ğŸ“„ E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json
          ğŸ“„ E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=7168,device_name=NVIDIA_H200.json
          ğŸ“„ E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=8192,device_name=AMD_Instinct_MI300X.json
          ğŸ“„ E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=8192,device_name=AMD_Instinct_MI325X.json
          ğŸ“„ E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json
          ğŸ“„ E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json
          ğŸ“„ README
          ğŸ“„ __init__.py
          ğŸ“„ causal_conv1d.py
          ğŸ“„ layernorm_gated.py
          ğŸ“„ mamba_ssm.py
          ğŸ“„ ssd_bmm.py
          ğŸ“„ ssd_chunk_scan.py
          ğŸ“„ ssd_chunk_state.py
          ğŸ“„ ssd_combined.py
          ğŸ“„ ssd_state_passing.py
          ğŸ“„ __init__.py
          ğŸ“„ compressed_tensors.py
          ğŸ“„ compressed_tensors_moe.py
          ğŸ“ schemes
          ğŸ“ transform
          ğŸ“„ triton_scaled_mm.py
          ğŸ“„ utils.py
          ğŸ“„ __init__.py
          ğŸ“ mixed_precision
          ğŸ“ scaled_mm
          ğŸ“„ __init__.py
          ğŸ“„ quark.py
          ğŸ“„ quark_moe.py
          ğŸ“ schemes
          ğŸ“„ utils.py
          ğŸ“„ __init__.py
          ğŸ“„ allspark_utils.py
          ğŸ“„ bitblas_utils.py
          ğŸ“ configs
          ğŸ“„ flashinfer_fp4_moe.py
          ğŸ“„ flashinfer_utils.py
          ğŸ“„ fp8_utils.py
          ğŸ“„ gptq_utils.py
          ğŸ“„ int8_utils.py
          ğŸ“„ layer_utils.py
          ğŸ“„ machete_utils.py
          ğŸ“„ marlin_utils.py
          ğŸ“„ marlin_utils_fp4.py
          ğŸ“„ marlin_utils_fp8.py
          ğŸ“„ marlin_utils_test.py
          ğŸ“„ marlin_utils_test_24.py
          ğŸ“„ mxfp4_utils.py
          ğŸ“„ mxfp6_utils.py
          ğŸ“„ mxfp8_utils.py
          ğŸ“„ nvfp4_emulation_utils.py
          ğŸ“„ nvfp4_moe_support.py
          ğŸ“„ ocp_mx_utils.py
          ğŸ“„ petit_utils.py
          ğŸ“„ quant_utils.py
          ğŸ“„ w8a8_utils.py
          ğŸ“„ __init__.py
          ğŸ“„ common.py
          ğŸ“„ cutlass_mla.py
          ğŸ“„ flashattn_mla.py
          ğŸ“„ flashinfer_mla.py
          ğŸ“„ flashmla.py
          ğŸ“„ flashmla_sparse.py
          ğŸ“„ indexer.py
          ğŸ“„ rocm_aiter_mla.py
          ğŸ“„ triton_mla.py
            ğŸ“„ __init__.py
            ğŸ“„ utils.py
            ğŸ“„ vllm_v1_adapter.py
            ğŸ“„ __init__.py
            ğŸ“„ p2p_nccl_connector.py
            ğŸ“„ p2p_nccl_engine.py
            ğŸ“„ tensor_memory_pool.py
            ğŸ“„ __init__.py
            ğŸ“„ compressed_tensors_24.py
            ğŸ“„ compressed_tensors_scheme.py
            ğŸ“„ compressed_tensors_w4a16_24.py
            ğŸ“„ compressed_tensors_w4a16_nvfp4.py
            ğŸ“„ compressed_tensors_w4a4_nvfp4.py
            ğŸ“„ compressed_tensors_w4a8_fp8.py
            ğŸ“„ compressed_tensors_w4a8_int.py
            ğŸ“„ compressed_tensors_w8a16_fp8.py
            ğŸ“„ compressed_tensors_w8a8_fp8.py
            ğŸ“„ compressed_tensors_w8a8_int8.py
            ğŸ“„ compressed_tensors_wNa16.py
            ğŸ“„ __init__.py
            ğŸ“„ linear.py
            ğŸ“„ module.py
            ğŸ“ schemes
            ğŸ“„ utils.py
            ğŸ“„ MPLinearKernel.py
            ğŸ“„ __init__.py
            ğŸ“„ allspark.py
            ğŸ“„ bitblas.py
            ğŸ“„ conch.py
            ğŸ“„ cutlass.py
            ğŸ“„ dynamic_4bit.py
            ğŸ“„ exllama.py
            ğŸ“„ machete.py
            ğŸ“„ marlin.py
            ğŸ“„ ScaledMMLinearKernel.py
            ğŸ“„ __init__.py
            ğŸ“„ aiter.py
            ğŸ“„ cpu.py
            ğŸ“„ cutlass.py
            ğŸ“„ triton.py
            ğŸ“„ xla.py
            ğŸ“„ __init__.py
            ğŸ“„ quark_ocp_mx.py
            ğŸ“„ quark_scheme.py
            ğŸ“„ quark_w8a8_fp8.py
            ğŸ“„ quark_w8a8_int8.py
            ğŸ“„ N=12288,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=12288,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2112,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2112,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4096,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4096,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json
            ğŸ“„ README.md
              ğŸ“„ __init__.py
              ğŸ“„ linear_qutlass_nvfp4.py
```
